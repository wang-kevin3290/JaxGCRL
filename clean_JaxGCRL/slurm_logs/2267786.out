Waiting for _ hour before starting...
Starting job execution...
-rwxr-xr-x 1 kw6487 student 37329 Nov  4 01:03 /scratch/network/kw6487/JaxGCRL/clean_JaxGCRL/train_crl_jax_brax.py
Arguments:
exp_name: train
seed: 263
torch_deterministic: True
cuda: True
track: True
wandb_project_name: clean_JaxGCRL_test
wandb_entity: wang-kevin3290-princeton-university
wandb_mode: offline
wandb_dir: .
wandb_group: .
capture_video: True
checkpoint: False
env_id: arm_reach
episode_length: 1000
obs_dim: 0
goal_start_idx: 0
goal_end_idx: 0
total_env_steps: 100000000
num_epochs: 100
num_envs: 512
num_eval_envs: 128
actor_lr: 0.0003
critic_lr: 0.0003
alpha_lr: 0.0003
batch_size: 1024
gamma: 0.99
logsumexp_penalty_coeff: 0.1
critic_batch_size_multiplier: 1.0
actor_batch_size_multiplier: 1.0
max_replay_size: 10000
min_replay_size: 1000
unroll_length: 62
same_network_width: 0
network_width: 256
critic_network_width: 1024
actor_network_width: 1024
num_episodes_per_env: 1
training_steps_multiplier: 1
use_all_batches: 0
num_sgd_batches_per_training_step: 400
mrn: 0
memory_bank: 0
memory_bank_size: 256
batchdiv2: 0
env_steps_per_actor_step: 0
num_prefill_env_steps: 0
num_prefill_actor_steps: 0
num_training_steps_per_epoch: 0


env_steps_per_actor_step: 31744
num_prefill_env_steps: 512000
num_prefill_actor_steps: 17.0
num_training_steps_per_epoch: 31
run_name: arm_reach_1024_critbx:1.0_actbx:1.0_batchdiv2:0_100000000_nenvs:512_criticwidth:1024_actorwidth:1024_epspenv:1_trainmult:1_mrn:0_memorybank:0_sgdbatchesptrainstep:400_useallbatches:0_263
wandb: Tracking run with wandb version 0.17.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
obs_size: 16, action_size: 4
x.shape: (1, 16)
data_size: 24
x.shape: (512, 16)
starting training....
x.shape: (512, 16)
buffer_state.data[:, envs_idxs, :].shape: (10000, 512, 24)
transitions.observation.shape (after 1 episodes per env): (512, 1000, 16)
transitions.observation.shape (after flatten_crl_fn): (512, 999, 16)
transitions.observation.shape (after first reshape): (511488, 16)
transitions.observation.shape (after ensuring divisibility by batch_size): (510976, 16)
transitions.observation.shape (after processing): (499, 1024, 16)
transitions.observation.shape (after 0, selecting 400 batches): (400, 1024, 16)
x.shape: (1024, 16)
x.shape: (128, 16)
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 0 out of 100 complete. metrics: {'eval/walltime': 53.34683036804199, 'training/sps': 5958.043652808032, 'training/walltime': 165.1656243801117, 'training/envsteps': 1523712.0, 'training/actor_loss': Array(6.0622582, dtype=float32), 'training/alph_aloss': Array(1.3379136, dtype=float32), 'training/buffer_current_size': Array(2976., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(6.7029686, dtype=float32), 'training/log_alpha': Array(-1.4061004, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.00079942, dtype=float32), 'training/sample_entropy': Array(1.6740059, dtype=float32), 'eval/episode_reward': Array(377.33594, dtype=float32), 'eval/episode_success': Array(377.33594, dtype=float32), 'eval/episode_success_easy': Array(810.7578, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 53.34683036804199, 'eval/sps': 2399.3927871051137}
Time elapsed: 0.061 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 1 out of 100 complete. metrics: {'eval/walltime': 86.41305208206177, 'training/sps': 7287.407954601119, 'training/walltime': 300.20184111595154, 'training/envsteps': 2507776.0, 'training/actor_loss': Array(5.409459, dtype=float32), 'training/alph_aloss': Array(0.02324028, dtype=float32), 'training/buffer_current_size': Array(4898., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.7838373, dtype=float32), 'training/log_alpha': Array(-3.1171706, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.02126706, dtype=float32), 'training/sample_entropy': Array(-1.5473278, dtype=float32), 'eval/episode_reward': Array(380.60156, dtype=float32), 'eval/episode_success': Array(380.60156, dtype=float32), 'eval/episode_success_easy': Array(748.4844, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.066221714019775, 'eval/sps': 3871.0198312657285}
Time elapsed: 0.107 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 2 out of 100 complete. metrics: {'eval/walltime': 120.17697978019714, 'training/sps': 7375.3288055687435, 'training/walltime': 433.6282992362976, 'training/envsteps': 3491840.0, 'training/actor_loss': Array(4.702046, dtype=float32), 'training/alph_aloss': Array(-0.00187366, dtype=float32), 'training/buffer_current_size': Array(6820., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0348873, dtype=float32), 'training/log_alpha': Array(-2.6472158, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07129981, dtype=float32), 'training/sample_entropy': Array(-2.0266201, dtype=float32), 'eval/episode_reward': Array(399.0625, dtype=float32), 'eval/episode_success': Array(399.0625, dtype=float32), 'eval/episode_success_easy': Array(671.8594, dtype=float32), 'eval/episode_success_any': Array(0.5234375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.763927698135376, 'eval/sps': 3791.028139391166}
Time elapsed: 0.154 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 3 out of 100 complete. metrics: {'eval/walltime': 156.2144913673401, 'training/sps': 7319.193751172411, 'training/walltime': 568.0780806541443, 'training/envsteps': 4475904.0, 'training/actor_loss': Array(4.547218, dtype=float32), 'training/alph_aloss': Array(-0.00135829, dtype=float32), 'training/buffer_current_size': Array(8742., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.826568, dtype=float32), 'training/log_alpha': Array(-2.3401573, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08738828, dtype=float32), 'training/sample_entropy': Array(-2.0146775, dtype=float32), 'eval/episode_reward': Array(372.08594, dtype=float32), 'eval/episode_success': Array(372.08594, dtype=float32), 'eval/episode_success_easy': Array(718.46875, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 36.037511587142944, 'eval/sps': 3551.8545638336027}
Time elapsed: 0.201 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 4 out of 100 complete. metrics: {'eval/walltime': 190.38006019592285, 'training/sps': 7310.597263366453, 'training/walltime': 702.6859607696533, 'training/envsteps': 5459968.0, 'training/actor_loss': Array(4.435522, dtype=float32), 'training/alph_aloss': Array(1.6448133e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.719865, dtype=float32), 'training/log_alpha': Array(-2.2785223, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09520076, dtype=float32), 'training/sample_entropy': Array(-1.9999537, dtype=float32), 'eval/episode_reward': Array(417.75, dtype=float32), 'eval/episode_success': Array(417.75, dtype=float32), 'eval/episode_success_easy': Array(733.97656, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.165568828582764, 'eval/sps': 3746.461844150997}
Time elapsed: 0.248 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 5 out of 100 complete. metrics: {'eval/walltime': 221.39767050743103, 'training/sps': 7306.971126996279, 'training/walltime': 837.360641002655, 'training/envsteps': 6444032.0, 'training/actor_loss': Array(4.4410014, dtype=float32), 'training/alph_aloss': Array(-0.00147101, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.6989646, dtype=float32), 'training/log_alpha': Array(-2.1421182, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10649966, dtype=float32), 'training/sample_entropy': Array(-2.0131166, dtype=float32), 'eval/episode_reward': Array(350.6172, dtype=float32), 'eval/episode_success': Array(350.6172, dtype=float32), 'eval/episode_success_easy': Array(802.09375, dtype=float32), 'eval/episode_success_any': Array(0.390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.01761031150818, 'eval/sps': 4126.687991579717}
Time elapsed: 0.294 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 6 out of 100 complete. metrics: {'eval/walltime': 249.04472184181213, 'training/sps': 7309.689330389481, 'training/walltime': 971.9852406978607, 'training/envsteps': 7428096.0, 'training/actor_loss': Array(4.4609056, dtype=float32), 'training/alph_aloss': Array(0.00198477, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7249866, dtype=float32), 'training/log_alpha': Array(-2.2077966, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10846866, dtype=float32), 'training/sample_entropy': Array(-1.9820575, dtype=float32), 'eval/episode_reward': Array(323.40625, dtype=float32), 'eval/episode_success': Array(323.40625, dtype=float32), 'eval/episode_success_easy': Array(765.0625, dtype=float32), 'eval/episode_success_any': Array(0.390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.647051334381104, 'eval/sps': 4629.788488178584}
Time elapsed: 0.339 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 7 out of 100 complete. metrics: {'eval/walltime': 277.79714488983154, 'training/sps': 7326.501137725584, 'training/walltime': 1106.3009231090546, 'training/envsteps': 8412160.0, 'training/actor_loss': Array(4.5944557, dtype=float32), 'training/alph_aloss': Array(0.00154663, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9382424, dtype=float32), 'training/log_alpha': Array(-2.4426317, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0978693, dtype=float32), 'training/sample_entropy': Array(-1.982604, dtype=float32), 'eval/episode_reward': Array(403.29688, dtype=float32), 'eval/episode_success': Array(403.29688, dtype=float32), 'eval/episode_success_easy': Array(835.3594, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.75242304801941, 'eval/sps': 4451.798715754399}
Time elapsed: 0.385 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 8 out of 100 complete. metrics: {'eval/walltime': 307.73937702178955, 'training/sps': 7314.999506804291, 'training/walltime': 1240.827794790268, 'training/envsteps': 9396224.0, 'training/actor_loss': Array(4.619359, dtype=float32), 'training/alph_aloss': Array(-0.00044994, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9811506, dtype=float32), 'training/log_alpha': Array(-2.510162, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09073675, dtype=float32), 'training/sample_entropy': Array(-2.0055242, dtype=float32), 'eval/episode_reward': Array(381.52344, dtype=float32), 'eval/episode_success': Array(381.52344, dtype=float32), 'eval/episode_success_easy': Array(803.97656, dtype=float32), 'eval/episode_success_any': Array(0.4140625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.942232131958008, 'eval/sps': 4274.898392207131}
Time elapsed: 0.430 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 9 out of 100 complete. metrics: {'eval/walltime': 338.01825642585754, 'training/sps': 7314.963246147436, 'training/walltime': 1375.355333328247, 'training/envsteps': 10380288.0, 'training/actor_loss': Array(4.5499306, dtype=float32), 'training/alph_aloss': Array(-0.00051977, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9041743, dtype=float32), 'training/log_alpha': Array(-2.417547, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08922905, dtype=float32), 'training/sample_entropy': Array(-2.0059376, dtype=float32), 'eval/episode_reward': Array(383.14062, dtype=float32), 'eval/episode_success': Array(383.14062, dtype=float32), 'eval/episode_success_easy': Array(882.02344, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.278879404067993, 'eval/sps': 4227.369127234051}
Time elapsed: 0.476 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 10 out of 100 complete. metrics: {'eval/walltime': 361.038494348526, 'training/sps': 7288.724069620508, 'training/walltime': 1510.3671667575836, 'training/envsteps': 11364352.0, 'training/actor_loss': Array(4.489265, dtype=float32), 'training/alph_aloss': Array(-0.00017389, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8433576, dtype=float32), 'training/log_alpha': Array(-2.3627782, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0873436, dtype=float32), 'training/sample_entropy': Array(-2.0019336, dtype=float32), 'eval/episode_reward': Array(432.83594, dtype=float32), 'eval/episode_success': Array(432.83594, dtype=float32), 'eval/episode_success_easy': Array(874.28125, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 23.020237922668457, 'eval/sps': 5560.324807675251}
Time elapsed: 0.520 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 11 out of 100 complete. metrics: {'eval/walltime': 391.907199382782, 'training/sps': 7280.8557583894135, 'training/walltime': 1645.5249054431915, 'training/envsteps': 12348416.0, 'training/actor_loss': Array(4.390513, dtype=float32), 'training/alph_aloss': Array(-5.8701313e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.762825, dtype=float32), 'training/log_alpha': Array(-2.3809059, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0866663, dtype=float32), 'training/sample_entropy': Array(-2.0006812, dtype=float32), 'eval/episode_reward': Array(374.5703, dtype=float32), 'eval/episode_success': Array(374.5703, dtype=float32), 'eval/episode_success_easy': Array(920.89844, dtype=float32), 'eval/episode_success_any': Array(0.4453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.86870503425598, 'eval/sps': 4146.59441845566}
Time elapsed: 0.566 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 12 out of 100 complete. metrics: {'eval/walltime': 422.31940388679504, 'training/sps': 7236.9922121894815, 'training/walltime': 1781.5018377304077, 'training/envsteps': 13332480.0, 'training/actor_loss': Array(4.2615786, dtype=float32), 'training/alph_aloss': Array(-0.00011777, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.668615, dtype=float32), 'training/log_alpha': Array(-2.380896, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08797405, dtype=float32), 'training/sample_entropy': Array(-2.0012786, dtype=float32), 'eval/episode_reward': Array(464.23438, dtype=float32), 'eval/episode_success': Array(464.23438, dtype=float32), 'eval/episode_success_easy': Array(843.2344, dtype=float32), 'eval/episode_success_any': Array(0.5, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.41220450401306, 'eval/sps': 4208.836619624522}
Time elapsed: 0.612 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 13 out of 100 complete. metrics: {'eval/walltime': 453.120512008667, 'training/sps': 7233.72144790507, 'training/walltime': 1917.5402526855469, 'training/envsteps': 14316544.0, 'training/actor_loss': Array(4.145542, dtype=float32), 'training/alph_aloss': Array(-0.00012557, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.5843296, dtype=float32), 'training/log_alpha': Array(-2.3175268, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09148698, dtype=float32), 'training/sample_entropy': Array(-2.0013492, dtype=float32), 'eval/episode_reward': Array(346.53906, dtype=float32), 'eval/episode_success': Array(346.53906, dtype=float32), 'eval/episode_success_easy': Array(773.58594, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.80110812187195, 'eval/sps': 4155.694642333561}
Time elapsed: 0.659 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 14 out of 100 complete. metrics: {'eval/walltime': 473.8154237270355, 'training/sps': 7224.094486998145, 'training/walltime': 2053.759954929352, 'training/envsteps': 15300608.0, 'training/actor_loss': Array(4.05691, dtype=float32), 'training/alph_aloss': Array(-0.00016836, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.5157413, dtype=float32), 'training/log_alpha': Array(-2.2885697, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09389105, dtype=float32), 'training/sample_entropy': Array(-2.0017369, dtype=float32), 'eval/episode_reward': Array(356.10156, dtype=float32), 'eval/episode_success': Array(356.10156, dtype=float32), 'eval/episode_success_easy': Array(743.0156, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 20.69491171836853, 'eval/sps': 6185.095241860292}
Time elapsed: 0.702 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 15 out of 100 complete. metrics: {'eval/walltime': 502.50804257392883, 'training/sps': 7206.248495807402, 'training/walltime': 2190.316999912262, 'training/envsteps': 16284672.0, 'training/actor_loss': Array(4.0033364, dtype=float32), 'training/alph_aloss': Array(0.00043328, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.481002, dtype=float32), 'training/log_alpha': Array(-2.313459, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09723107, dtype=float32), 'training/sample_entropy': Array(-1.9956279, dtype=float32), 'eval/episode_reward': Array(389.53906, dtype=float32), 'eval/episode_success': Array(389.53906, dtype=float32), 'eval/episode_success_easy': Array(743.0625, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.69261884689331, 'eval/sps': 4461.077627072692}
Time elapsed: 0.748 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 16 out of 100 complete. metrics: {'eval/walltime': 535.8221771717072, 'training/sps': 7177.793437012946, 'training/walltime': 2327.415400505066, 'training/envsteps': 17268736.0, 'training/actor_loss': Array(4.021547, dtype=float32), 'training/alph_aloss': Array(0.00070124, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.515359, dtype=float32), 'training/log_alpha': Array(-2.4203267, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09954745, dtype=float32), 'training/sample_entropy': Array(-1.9921781, dtype=float32), 'eval/episode_reward': Array(392.92188, dtype=float32), 'eval/episode_success': Array(392.92188, dtype=float32), 'eval/episode_success_easy': Array(757.7422, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.31413459777832, 'eval/sps': 3842.2129689220915}
Time elapsed: 0.795 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 17 out of 100 complete. metrics: {'eval/walltime': 568.3288369178772, 'training/sps': 7218.282306845647, 'training/walltime': 2463.7447872161865, 'training/envsteps': 18252800.0, 'training/actor_loss': Array(4.048964, dtype=float32), 'training/alph_aloss': Array(0.00013252, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.550451, dtype=float32), 'training/log_alpha': Array(-2.5120432, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10070864, dtype=float32), 'training/sample_entropy': Array(-1.9984355, dtype=float32), 'eval/episode_reward': Array(452.28906, dtype=float32), 'eval/episode_success': Array(452.28906, dtype=float32), 'eval/episode_success_easy': Array(851.59375, dtype=float32), 'eval/episode_success_any': Array(0.5546875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.506659746170044, 'eval/sps': 3937.6546529078873}
Time elapsed: 0.842 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 18 out of 100 complete. metrics: {'eval/walltime': 600.4944067001343, 'training/sps': 7219.397739592302, 'training/walltime': 2600.0531103610992, 'training/envsteps': 19236864.0, 'training/actor_loss': Array(4.012313, dtype=float32), 'training/alph_aloss': Array(-0.00023291, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.5139527, dtype=float32), 'training/log_alpha': Array(-2.481687, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1016995, dtype=float32), 'training/sample_entropy': Array(-2.0028307, dtype=float32), 'eval/episode_reward': Array(420.46875, dtype=float32), 'eval/episode_success': Array(420.46875, dtype=float32), 'eval/episode_success_easy': Array(751.2578, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.16556978225708, 'eval/sps': 3979.4103094236607}
Time elapsed: 0.889 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 19 out of 100 complete. metrics: {'eval/walltime': 633.1666235923767, 'training/sps': 7175.945703813795, 'training/walltime': 2737.186812400818, 'training/envsteps': 20220928.0, 'training/actor_loss': Array(3.965698, dtype=float32), 'training/alph_aloss': Array(-4.1498093e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.470954, dtype=float32), 'training/log_alpha': Array(-2.4513187, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10260908, dtype=float32), 'training/sample_entropy': Array(-2.0005264, dtype=float32), 'eval/episode_reward': Array(366.67188, dtype=float32), 'eval/episode_success': Array(366.67188, dtype=float32), 'eval/episode_success_easy': Array(696.3594, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.67221689224243, 'eval/sps': 3917.701710360274}
Time elapsed: 0.936 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 20 out of 100 complete. metrics: {'eval/walltime': 666.2591161727905, 'training/sps': 7195.6658641979975, 'training/walltime': 2873.944691181183, 'training/envsteps': 21204992.0, 'training/actor_loss': Array(3.9357476, dtype=float32), 'training/alph_aloss': Array(9.157876e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.448323, dtype=float32), 'training/log_alpha': Array(-2.460761, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10118956, dtype=float32), 'training/sample_entropy': Array(-1.9989712, dtype=float32), 'eval/episode_reward': Array(337.08594, dtype=float32), 'eval/episode_success': Array(337.08594, dtype=float32), 'eval/episode_success_easy': Array(758.0469, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.09249258041382, 'eval/sps': 3867.9467764165433}
Time elapsed: 0.983 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 21 out of 100 complete. metrics: {'eval/walltime': 697.2420334815979, 'training/sps': 7202.430349268064, 'training/walltime': 3010.574127674103, 'training/envsteps': 22189056.0, 'training/actor_loss': Array(3.941419, dtype=float32), 'training/alph_aloss': Array(0.00010076, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.4679832, dtype=float32), 'training/log_alpha': Array(-2.475406, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09872124, dtype=float32), 'training/sample_entropy': Array(-1.9988434, dtype=float32), 'eval/episode_reward': Array(388.96875, dtype=float32), 'eval/episode_success': Array(388.96875, dtype=float32), 'eval/episode_success_easy': Array(781.4297, dtype=float32), 'eval/episode_success_any': Array(0.515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.982917308807373, 'eval/sps': 4131.308834614293}
Time elapsed: 1.030 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 22 out of 100 complete. metrics: {'eval/walltime': 727.4816443920135, 'training/sps': 7163.8258717119625, 'training/walltime': 3147.939833879471, 'training/envsteps': 23173120.0, 'training/actor_loss': Array(3.9700253, dtype=float32), 'training/alph_aloss': Array(0.00014414, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.523226, dtype=float32), 'training/log_alpha': Array(-2.5061245, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09493215, dtype=float32), 'training/sample_entropy': Array(-1.9982842, dtype=float32), 'eval/episode_reward': Array(362.16406, dtype=float32), 'eval/episode_success': Array(362.16406, dtype=float32), 'eval/episode_success_easy': Array(798.8125, dtype=float32), 'eval/episode_success_any': Array(0.46875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.23961091041565, 'eval/sps': 4232.8586958078895}
Time elapsed: 1.077 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 23 out of 100 complete. metrics: {'eval/walltime': 759.397970199585, 'training/sps': 7064.899201495023, 'training/walltime': 3287.2290115356445, 'training/envsteps': 24157184.0, 'training/actor_loss': Array(3.994294, dtype=float32), 'training/alph_aloss': Array(6.747005e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.570751, dtype=float32), 'training/log_alpha': Array(-2.5217953, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09164148, dtype=float32), 'training/sample_entropy': Array(-1.9991999, dtype=float32), 'eval/episode_reward': Array(331.04688, dtype=float32), 'eval/episode_success': Array(331.04688, dtype=float32), 'eval/episode_success_easy': Array(864.2344, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.91632580757141, 'eval/sps': 4010.4866948574313}
Time elapsed: 1.124 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 24 out of 100 complete. metrics: {'eval/walltime': 790.2978010177612, 'training/sps': 7155.463165561746, 'training/walltime': 3424.7552592754364, 'training/envsteps': 25141248.0, 'training/actor_loss': Array(4.0246496, dtype=float32), 'training/alph_aloss': Array(-0.00014568, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.6136513, dtype=float32), 'training/log_alpha': Array(-2.5139477, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0885164, dtype=float32), 'training/sample_entropy': Array(-2.001832, dtype=float32), 'eval/episode_reward': Array(483.95312, dtype=float32), 'eval/episode_success': Array(483.95312, dtype=float32), 'eval/episode_success_easy': Array(843.91406, dtype=float32), 'eval/episode_success_any': Array(0.53125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.89983081817627, 'eval/sps': 4142.417502321932}
Time elapsed: 1.171 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 25 out of 100 complete. metrics: {'eval/walltime': 813.8263075351715, 'training/sps': 7067.868530327273, 'training/walltime': 3563.985919237137, 'training/envsteps': 26125312.0, 'training/actor_loss': Array(4.037281, dtype=float32), 'training/alph_aloss': Array(-7.347099e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.6340556, dtype=float32), 'training/log_alpha': Array(-2.48679, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08542892, dtype=float32), 'training/sample_entropy': Array(-2.000922, dtype=float32), 'eval/episode_reward': Array(304.3047, dtype=float32), 'eval/episode_success': Array(304.3047, dtype=float32), 'eval/episode_success_easy': Array(804.5625, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 23.52850651741028, 'eval/sps': 5440.209301227192}
Time elapsed: 1.216 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 26 out of 100 complete. metrics: {'eval/walltime': 846.4871270656586, 'training/sps': 7148.466793539, 'training/walltime': 3701.646767139435, 'training/envsteps': 27109376.0, 'training/actor_loss': Array(4.033003, dtype=float32), 'training/alph_aloss': Array(-3.3321372e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.6372666, dtype=float32), 'training/log_alpha': Array(-2.4721718, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08405168, dtype=float32), 'training/sample_entropy': Array(-2.0004365, dtype=float32), 'eval/episode_reward': Array(389.6875, dtype=float32), 'eval/episode_success': Array(389.6875, dtype=float32), 'eval/episode_success_easy': Array(835.7031, dtype=float32), 'eval/episode_success_any': Array(0.5078125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.66081953048706, 'eval/sps': 3919.068836607701}
Time elapsed: 1.263 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 27 out of 100 complete. metrics: {'eval/walltime': 879.8046116828918, 'training/sps': 7061.117712238846, 'training/walltime': 3841.010539293289, 'training/envsteps': 28093440.0, 'training/actor_loss': Array(4.04687, dtype=float32), 'training/alph_aloss': Array(8.706701e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.655302, dtype=float32), 'training/log_alpha': Array(-2.4558902, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08279716, dtype=float32), 'training/sample_entropy': Array(-1.999941, dtype=float32), 'eval/episode_reward': Array(467.35938, dtype=float32), 'eval/episode_success': Array(467.35938, dtype=float32), 'eval/episode_success_easy': Array(853.46875, dtype=float32), 'eval/episode_success_any': Array(0.515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.317484617233276, 'eval/sps': 3841.826640591971}
Time elapsed: 1.311 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 28 out of 100 complete. metrics: {'eval/walltime': 908.4108099937439, 'training/sps': 7151.309041314441, 'training/walltime': 3978.6166746616364, 'training/envsteps': 29077504.0, 'training/actor_loss': Array(4.0869412, dtype=float32), 'training/alph_aloss': Array(-4.6507233e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7019944, dtype=float32), 'training/log_alpha': Array(-2.4617856, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07999891, dtype=float32), 'training/sample_entropy': Array(-2.000592, dtype=float32), 'eval/episode_reward': Array(367.71875, dtype=float32), 'eval/episode_success': Array(367.71875, dtype=float32), 'eval/episode_success_easy': Array(820.47656, dtype=float32), 'eval/episode_success_any': Array(0.46875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.60619831085205, 'eval/sps': 4474.554731428325}
Time elapsed: 1.358 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 29 out of 100 complete. metrics: {'eval/walltime': 939.852906703949, 'training/sps': 7036.379254979986, 'training/walltime': 4118.470421075821, 'training/envsteps': 30061568.0, 'training/actor_loss': Array(4.1257343, dtype=float32), 'training/alph_aloss': Array(-0.00015226, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7433085, dtype=float32), 'training/log_alpha': Array(-2.4442647, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07931093, dtype=float32), 'training/sample_entropy': Array(-2.001797, dtype=float32), 'eval/episode_reward': Array(476.07812, dtype=float32), 'eval/episode_success': Array(476.07812, dtype=float32), 'eval/episode_success_easy': Array(795.97656, dtype=float32), 'eval/episode_success_any': Array(0.5625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.442096710205078, 'eval/sps': 4070.975329022997}
Time elapsed: 1.405 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 30 out of 100 complete. metrics: {'eval/walltime': 970.0087652206421, 'training/sps': 7127.150865474879, 'training/walltime': 4256.542985916138, 'training/envsteps': 31045632.0, 'training/actor_loss': Array(4.165339, dtype=float32), 'training/alph_aloss': Array(0.00020427, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7914815, dtype=float32), 'training/log_alpha': Array(-2.453046, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07889698, dtype=float32), 'training/sample_entropy': Array(-1.99768, dtype=float32), 'eval/episode_reward': Array(387.78906, dtype=float32), 'eval/episode_success': Array(387.78906, dtype=float32), 'eval/episode_success_easy': Array(880.5156, dtype=float32), 'eval/episode_success_any': Array(0.515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.155858516693115, 'eval/sps': 4244.614688357958}
Time elapsed: 1.452 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 31 out of 100 complete. metrics: {'eval/walltime': 999.0290966033936, 'training/sps': 7038.80735253753, 'training/walltime': 4396.34848856926, 'training/envsteps': 32029696.0, 'training/actor_loss': Array(4.2050767, dtype=float32), 'training/alph_aloss': Array(9.850114e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8416944, dtype=float32), 'training/log_alpha': Array(-2.4826567, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07944805, dtype=float32), 'training/sample_entropy': Array(-1.9988688, dtype=float32), 'eval/episode_reward': Array(301.52344, dtype=float32), 'eval/episode_success': Array(301.52344, dtype=float32), 'eval/episode_success_easy': Array(798.3125, dtype=float32), 'eval/episode_success_any': Array(0.3828125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.020331382751465, 'eval/sps': 4410.70083975947}
Time elapsed: 1.499 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 32 out of 100 complete. metrics: {'eval/walltime': 1030.256603717804, 'training/sps': 7146.427952043425, 'training/walltime': 4534.048610448837, 'training/envsteps': 33013760.0, 'training/actor_loss': Array(4.230775, dtype=float32), 'training/alph_aloss': Array(-1.8346993e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8761606, dtype=float32), 'training/log_alpha': Array(-2.4921434, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08053221, dtype=float32), 'training/sample_entropy': Array(-2.0002615, dtype=float32), 'eval/episode_reward': Array(424.71094, dtype=float32), 'eval/episode_success': Array(424.71094, dtype=float32), 'eval/episode_success_easy': Array(835.09375, dtype=float32), 'eval/episode_success_any': Array(0.5, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.2275071144104, 'eval/sps': 4098.950311052286}
Time elapsed: 1.546 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 33 out of 100 complete. metrics: {'eval/walltime': 1051.9599735736847, 'training/sps': 7024.041368294655, 'training/walltime': 4674.148013114929, 'training/envsteps': 33997824.0, 'training/actor_loss': Array(4.2539554, dtype=float32), 'training/alph_aloss': Array(9.330429e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9063535, dtype=float32), 'training/log_alpha': Array(-2.4932086, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08164894, dtype=float32), 'training/sample_entropy': Array(-1.9989177, dtype=float32), 'eval/episode_reward': Array(386.04688, dtype=float32), 'eval/episode_success': Array(386.04688, dtype=float32), 'eval/episode_success_easy': Array(783.6328, dtype=float32), 'eval/episode_success_any': Array(0.5390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 21.703369855880737, 'eval/sps': 5897.7016403430625}
Time elapsed: 1.591 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 34 out of 100 complete. metrics: {'eval/walltime': 1080.6232135295868, 'training/sps': 7140.599835845201, 'training/walltime': 4811.960525035858, 'training/envsteps': 34981888.0, 'training/actor_loss': Array(4.2795415, dtype=float32), 'training/alph_aloss': Array(-5.2294163e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9338713, dtype=float32), 'training/log_alpha': Array(-2.483522, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08318854, dtype=float32), 'training/sample_entropy': Array(-2.000679, dtype=float32), 'eval/episode_reward': Array(288.85156, dtype=float32), 'eval/episode_success': Array(288.85156, dtype=float32), 'eval/episode_success_easy': Array(713.5625, dtype=float32), 'eval/episode_success_any': Array(0.375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.6632399559021, 'eval/sps': 4465.650086903148}
Time elapsed: 1.637 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 35 out of 100 complete. metrics: {'eval/walltime': 1115.5416238307953, 'training/sps': 7053.6200118696, 'training/walltime': 4951.472434997559, 'training/envsteps': 35965952.0, 'training/actor_loss': Array(4.29934, dtype=float32), 'training/alph_aloss': Array(-6.792346e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.96393, dtype=float32), 'training/log_alpha': Array(-2.4782045, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08355431, dtype=float32), 'training/sample_entropy': Array(-2.0008557, dtype=float32), 'eval/episode_reward': Array(400.48438, dtype=float32), 'eval/episode_success': Array(400.48438, dtype=float32), 'eval/episode_success_easy': Array(741.5547, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.918410301208496, 'eval/sps': 3665.688068152691}
Time elapsed: 1.685 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 36 out of 100 complete. metrics: {'eval/walltime': 1150.3363847732544, 'training/sps': 7136.718103200414, 'training/walltime': 5089.359904527664, 'training/envsteps': 36950016.0, 'training/actor_loss': Array(4.326069, dtype=float32), 'training/alph_aloss': Array(5.20559e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.999164, dtype=float32), 'training/log_alpha': Array(-2.482162, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08332652, dtype=float32), 'training/sample_entropy': Array(-1.9994229, dtype=float32), 'eval/episode_reward': Array(319.96875, dtype=float32), 'eval/episode_success': Array(319.96875, dtype=float32), 'eval/episode_success_easy': Array(765.59375, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.794760942459106, 'eval/sps': 3678.7147413277685}
Time elapsed: 1.733 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 37 out of 100 complete. metrics: {'eval/walltime': 1184.951169013977, 'training/sps': 7041.831745759183, 'training/walltime': 5229.105362176895, 'training/envsteps': 37934080.0, 'training/actor_loss': Array(4.357272, dtype=float32), 'training/alph_aloss': Array(7.5387485e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0361934, dtype=float32), 'training/log_alpha': Array(-2.4899337, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08240189, dtype=float32), 'training/sample_entropy': Array(-1.9991335, dtype=float32), 'eval/episode_reward': Array(381.1328, dtype=float32), 'eval/episode_success': Array(381.1328, dtype=float32), 'eval/episode_success_easy': Array(810.0625, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.614784240722656, 'eval/sps': 3697.841913728125}
Time elapsed: 1.782 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 38 out of 100 complete. metrics: {'eval/walltime': 1218.754622220993, 'training/sps': 7161.210787322573, 'training/walltime': 5366.521230697632, 'training/envsteps': 38918144.0, 'training/actor_loss': Array(4.3740664, dtype=float32), 'training/alph_aloss': Array(-7.7721976e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.052443, dtype=float32), 'training/log_alpha': Array(-2.4915996, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08202438, dtype=float32), 'training/sample_entropy': Array(-2.00098, dtype=float32), 'eval/episode_reward': Array(422.95312, dtype=float32), 'eval/episode_success': Array(422.95312, dtype=float32), 'eval/episode_success_easy': Array(790.4922, dtype=float32), 'eval/episode_success_any': Array(0.6015625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.80345320701599, 'eval/sps': 3786.595387640257}
Time elapsed: 1.829 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 39 out of 100 complete. metrics: {'eval/walltime': 1247.6283378601074, 'training/sps': 7061.572622588618, 'training/walltime': 5505.876024961472, 'training/envsteps': 39902208.0, 'training/actor_loss': Array(4.377914, dtype=float32), 'training/alph_aloss': Array(2.3876131e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.059081, dtype=float32), 'training/log_alpha': Array(-2.481846, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.08104845, dtype=float32), 'training/sample_entropy': Array(-1.9997579, dtype=float32), 'eval/episode_reward': Array(350.8672, dtype=float32), 'eval/episode_success': Array(350.8672, dtype=float32), 'eval/episode_success_easy': Array(739.9453, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.87371563911438, 'eval/sps': 4433.097617218414}
Time elapsed: 1.876 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 40 out of 100 complete. metrics: {'eval/walltime': 1275.0439321994781, 'training/sps': 7135.955278909834, 'training/walltime': 5643.7782344818115, 'training/envsteps': 40886272.0, 'training/actor_loss': Array(4.3705506, dtype=float32), 'training/alph_aloss': Array(-6.6155735e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0499573, dtype=float32), 'training/log_alpha': Array(-2.480548, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07965481, dtype=float32), 'training/sample_entropy': Array(-2.0008295, dtype=float32), 'eval/episode_reward': Array(388.25, dtype=float32), 'eval/episode_success': Array(388.25, dtype=float32), 'eval/episode_success_easy': Array(729.35156, dtype=float32), 'eval/episode_success_any': Array(0.46875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.415594339370728, 'eval/sps': 4668.875619310685}
Time elapsed: 1.922 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 41 out of 100 complete. metrics: {'eval/walltime': 1303.059736251831, 'training/sps': 7037.950537154, 'training/walltime': 5783.600757360458, 'training/envsteps': 41870336.0, 'training/actor_loss': Array(4.3542137, dtype=float32), 'training/alph_aloss': Array(-6.224233e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0369935, dtype=float32), 'training/log_alpha': Array(-2.459448, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07923447, dtype=float32), 'training/sample_entropy': Array(-2.0007703, dtype=float32), 'eval/episode_reward': Array(442.10156, dtype=float32), 'eval/episode_success': Array(442.10156, dtype=float32), 'eval/episode_success_easy': Array(786.8906, dtype=float32), 'eval/episode_success_any': Array(0.578125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.015804052352905, 'eval/sps': 4568.849773535232}
Time elapsed: 1.969 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 42 out of 100 complete. metrics: {'eval/walltime': 1330.2195284366608, 'training/sps': 7135.443526377375, 'training/walltime': 5921.512857198715, 'training/envsteps': 42854400.0, 'training/actor_loss': Array(4.349036, dtype=float32), 'training/alph_aloss': Array(-0.00010027, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.031227, dtype=float32), 'training/log_alpha': Array(-2.440297, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07810467, dtype=float32), 'training/sample_entropy': Array(-2.0011857, dtype=float32), 'eval/episode_reward': Array(370.2578, dtype=float32), 'eval/episode_success': Array(370.2578, dtype=float32), 'eval/episode_success_easy': Array(763.9531, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.159792184829712, 'eval/sps': 4712.849020674586}
Time elapsed: 2.014 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 43 out of 100 complete. metrics: {'eval/walltime': 1357.3659846782684, 'training/sps': 7026.146703189924, 'training/walltime': 6061.570280075073, 'training/envsteps': 43838464.0, 'training/actor_loss': Array(4.3502994, dtype=float32), 'training/alph_aloss': Array(1.1970142e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0312257, dtype=float32), 'training/log_alpha': Array(-2.4259763, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07731763, dtype=float32), 'training/sample_entropy': Array(-1.9999156, dtype=float32), 'eval/episode_reward': Array(349.91406, dtype=float32), 'eval/episode_success': Array(349.91406, dtype=float32), 'eval/episode_success_easy': Array(747.8672, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.146456241607666, 'eval/sps': 4715.164250566637}
Time elapsed: 2.061 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 44 out of 100 complete. metrics: {'eval/walltime': 1385.6506786346436, 'training/sps': 7118.329639770364, 'training/walltime': 6199.8139481544495, 'training/envsteps': 44822528.0, 'training/actor_loss': Array(4.36221, dtype=float32), 'training/alph_aloss': Array(-4.148641e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0454364, dtype=float32), 'training/log_alpha': Array(-2.42114, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0767866, dtype=float32), 'training/sample_entropy': Array(-2.0005121, dtype=float32), 'eval/episode_reward': Array(390.375, dtype=float32), 'eval/episode_success': Array(390.375, dtype=float32), 'eval/episode_success_easy': Array(751.6328, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.284693956375122, 'eval/sps': 4525.415767178556}
Time elapsed: 2.107 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 45 out of 100 complete. metrics: {'eval/walltime': 1416.0285470485687, 'training/sps': 7055.362103046847, 'training/walltime': 6339.291410207748, 'training/envsteps': 45806592.0, 'training/actor_loss': Array(4.388262, dtype=float32), 'training/alph_aloss': Array(2.6789896e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.071739, dtype=float32), 'training/log_alpha': Array(-2.4111185, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07588108, dtype=float32), 'training/sample_entropy': Array(-1.9997506, dtype=float32), 'eval/episode_reward': Array(369.46094, dtype=float32), 'eval/episode_success': Array(369.46094, dtype=float32), 'eval/episode_success_easy': Array(778.625, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.37786841392517, 'eval/sps': 4213.593865635582}
Time elapsed: 2.154 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 46 out of 100 complete. metrics: {'eval/walltime': 1446.5170974731445, 'training/sps': 7143.000424463243, 'training/walltime': 6477.0576066970825, 'training/envsteps': 46790656.0, 'training/actor_loss': Array(4.413642, dtype=float32), 'training/alph_aloss': Array(-0.00012519, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0884295, dtype=float32), 'training/log_alpha': Array(-2.4050906, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07496458, dtype=float32), 'training/sample_entropy': Array(-2.001435, dtype=float32), 'eval/episode_reward': Array(385.15625, dtype=float32), 'eval/episode_success': Array(385.15625, dtype=float32), 'eval/episode_success_easy': Array(693.21094, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.488550424575806, 'eval/sps': 4198.297335147277}
Time elapsed: 2.201 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 47 out of 100 complete. metrics: {'eval/walltime': 1479.1831314563751, 'training/sps': 7054.840633394464, 'training/walltime': 6616.545378446579, 'training/envsteps': 47774720.0, 'training/actor_loss': Array(4.441612, dtype=float32), 'training/alph_aloss': Array(2.5433788e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.1135674, dtype=float32), 'training/log_alpha': Array(-2.3952594, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07276998, dtype=float32), 'training/sample_entropy': Array(-1.9997798, dtype=float32), 'eval/episode_reward': Array(321.7578, dtype=float32), 'eval/episode_success': Array(321.7578, dtype=float32), 'eval/episode_success_easy': Array(723.40625, dtype=float32), 'eval/episode_success_any': Array(0.5, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.66603398323059, 'eval/sps': 3918.4432387999714}
Time elapsed: 2.249 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 48 out of 100 complete. metrics: {'eval/walltime': 1498.9129371643066, 'training/sps': 7154.218007657585, 'training/walltime': 6754.095561981201, 'training/envsteps': 48758784.0, 'training/actor_loss': Array(4.4496017, dtype=float32), 'training/alph_aloss': Array(-0.00012278, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.1129823, dtype=float32), 'training/log_alpha': Array(-2.3796875, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07177897, dtype=float32), 'training/sample_entropy': Array(-2.0013802, dtype=float32), 'eval/episode_reward': Array(327.85938, dtype=float32), 'eval/episode_success': Array(327.85938, dtype=float32), 'eval/episode_success_easy': Array(760.1875, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 19.72980570793152, 'eval/sps': 6487.646249275689}
Time elapsed: 2.293 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 49 out of 100 complete. metrics: {'eval/walltime': 1530.798752784729, 'training/sps': 7063.079043506536, 'training/walltime': 6893.420634508133, 'training/envsteps': 49742848.0, 'training/actor_loss': Array(4.457949, dtype=float32), 'training/alph_aloss': Array(3.031338e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.112394, dtype=float32), 'training/log_alpha': Array(-2.3684068, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07025757, dtype=float32), 'training/sample_entropy': Array(-1.9997286, dtype=float32), 'eval/episode_reward': Array(274.5625, dtype=float32), 'eval/episode_success': Array(274.5625, dtype=float32), 'eval/episode_success_easy': Array(693.7656, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.885815620422363, 'eval/sps': 4014.3241598003224}
Time elapsed: 2.340 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 50 out of 100 complete. metrics: {'eval/walltime': 1564.3910689353943, 'training/sps': 7168.670788451674, 'training/walltime': 7030.693502664566, 'training/envsteps': 50726912.0, 'training/actor_loss': Array(4.463404, dtype=float32), 'training/alph_aloss': Array(4.4375956e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.117013, dtype=float32), 'training/log_alpha': Array(-2.3707535, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06854455, dtype=float32), 'training/sample_entropy': Array(-1.9995778, dtype=float32), 'eval/episode_reward': Array(356.4922, dtype=float32), 'eval/episode_success': Array(356.4922, dtype=float32), 'eval/episode_success_easy': Array(844.8594, dtype=float32), 'eval/episode_success_any': Array(0.5546875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.59231615066528, 'eval/sps': 3810.3951935289524}
Time elapsed: 2.388 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 51 out of 100 complete. metrics: {'eval/walltime': 1598.3135821819305, 'training/sps': 7071.319005263474, 'training/walltime': 7169.856224536896, 'training/envsteps': 51710976.0, 'training/actor_loss': Array(4.4731455, dtype=float32), 'training/alph_aloss': Array(4.461549e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.1260347, dtype=float32), 'training/log_alpha': Array(-2.3787215, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06720148, dtype=float32), 'training/sample_entropy': Array(-1.9995705, dtype=float32), 'eval/episode_reward': Array(365.34375, dtype=float32), 'eval/episode_success': Array(365.34375, dtype=float32), 'eval/episode_success_easy': Array(757.9297, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.922513246536255, 'eval/sps': 3773.305328816395}
Time elapsed: 2.436 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 52 out of 100 complete. metrics: {'eval/walltime': 1628.8018283843994, 'training/sps': 7144.378908424746, 'training/walltime': 7307.595839500427, 'training/envsteps': 52695040.0, 'training/actor_loss': Array(4.4718895, dtype=float32), 'training/alph_aloss': Array(0.00024597, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.129609, dtype=float32), 'training/log_alpha': Array(-2.40906, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0654967, dtype=float32), 'training/sample_entropy': Array(-1.9973112, dtype=float32), 'eval/episode_reward': Array(300.64062, dtype=float32), 'eval/episode_success': Array(300.64062, dtype=float32), 'eval/episode_success_easy': Array(770.5, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.488246202468872, 'eval/sps': 4198.339227188307}
Time elapsed: 2.482 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 53 out of 100 complete. metrics: {'eval/walltime': 1660.1268463134766, 'training/sps': 7067.595520994966, 'training/walltime': 7446.831877708435, 'training/envsteps': 53679104.0, 'training/actor_loss': Array(4.4744134, dtype=float32), 'training/alph_aloss': Array(0.00010735, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.134889, dtype=float32), 'training/log_alpha': Array(-2.434876, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06392421, dtype=float32), 'training/sample_entropy': Array(-1.9988147, dtype=float32), 'eval/episode_reward': Array(308.02344, dtype=float32), 'eval/episode_success': Array(308.02344, dtype=float32), 'eval/episode_success_easy': Array(744.2578, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.32501792907715, 'eval/sps': 4086.1907977133264}
Time elapsed: 2.530 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 54 out of 100 complete. metrics: {'eval/walltime': 1690.5360128879547, 'training/sps': 7161.189702486489, 'training/walltime': 7584.2481508255005, 'training/envsteps': 54663168.0, 'training/actor_loss': Array(4.4788685, dtype=float32), 'training/alph_aloss': Array(0.0001186, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.138085, dtype=float32), 'training/log_alpha': Array(-2.4721518, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06324597, dtype=float32), 'training/sample_entropy': Array(-1.998651, dtype=float32), 'eval/episode_reward': Array(288.4453, dtype=float32), 'eval/episode_success': Array(288.4453, dtype=float32), 'eval/episode_success_easy': Array(726.27344, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.40916657447815, 'eval/sps': 4209.257089848297}
Time elapsed: 2.576 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 55 out of 100 complete. metrics: {'eval/walltime': 1726.04843211174, 'training/sps': 7064.78254369067, 'training/walltime': 7723.539628505707, 'training/envsteps': 55647232.0, 'training/actor_loss': Array(4.462936, dtype=float32), 'training/alph_aloss': Array(9.502826e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.119577, dtype=float32), 'training/log_alpha': Array(-2.487579, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06309754, dtype=float32), 'training/sample_entropy': Array(-1.9999336, dtype=float32), 'eval/episode_reward': Array(398.33594, dtype=float32), 'eval/episode_success': Array(398.33594, dtype=float32), 'eval/episode_success_easy': Array(848.7422, dtype=float32), 'eval/episode_success_any': Array(0.5859375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 35.5124192237854, 'eval/sps': 3604.372858784809}
Time elapsed: 2.625 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 56 out of 100 complete. metrics: {'eval/walltime': 1754.7377650737762, 'training/sps': 7142.98470041896, 'training/walltime': 7861.3061282634735, 'training/envsteps': 56631296.0, 'training/actor_loss': Array(4.441005, dtype=float32), 'training/alph_aloss': Array(6.133517e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.091259, dtype=float32), 'training/log_alpha': Array(-2.4869692, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06565885, dtype=float32), 'training/sample_entropy': Array(-1.9993143, dtype=float32), 'eval/episode_reward': Array(347.9453, dtype=float32), 'eval/episode_success': Array(347.9453, dtype=float32), 'eval/episode_success_easy': Array(813.9219, dtype=float32), 'eval/episode_success_any': Array(0.5078125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.689332962036133, 'eval/sps': 4461.588569151439}
Time elapsed: 2.671 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 57 out of 100 complete. metrics: {'eval/walltime': 1788.205731868744, 'training/sps': 7078.035533098042, 'training/walltime': 8000.336795091629, 'training/envsteps': 57615360.0, 'training/actor_loss': Array(4.4180894, dtype=float32), 'training/alph_aloss': Array(0.00013575, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0639462, dtype=float32), 'training/log_alpha': Array(-2.500105, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06744837, dtype=float32), 'training/sample_entropy': Array(-1.9983903, dtype=float32), 'eval/episode_reward': Array(309.54688, dtype=float32), 'eval/episode_success': Array(309.54688, dtype=float32), 'eval/episode_success_easy': Array(864.58594, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.46796679496765, 'eval/sps': 3824.5526172580785}
Time elapsed: 2.719 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 58 out of 100 complete. metrics: {'eval/walltime': 1813.3431255817413, 'training/sps': 7183.050571925974, 'training/walltime': 8137.334856033325, 'training/envsteps': 58599424.0, 'training/actor_loss': Array(4.404027, dtype=float32), 'training/alph_aloss': Array(0.00011349, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.046788, dtype=float32), 'training/log_alpha': Array(-2.529723, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06867629, dtype=float32), 'training/sample_entropy': Array(-1.9986211, dtype=float32), 'eval/episode_reward': Array(289.71094, dtype=float32), 'eval/episode_success': Array(289.71094, dtype=float32), 'eval/episode_success_easy': Array(845.1094, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 25.137393712997437, 'eval/sps': 5092.015563006314}
Time elapsed: 2.764 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 59 out of 100 complete. metrics: {'eval/walltime': 1844.0736691951752, 'training/sps': 7098.988080679195, 'training/walltime': 8275.955176115036, 'training/envsteps': 59583488.0, 'training/actor_loss': Array(4.3839684, dtype=float32), 'training/alph_aloss': Array(0.00013719, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.0233088, dtype=float32), 'training/log_alpha': Array(-2.5593467, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0700809, dtype=float32), 'training/sample_entropy': Array(-1.9982661, dtype=float32), 'eval/episode_reward': Array(382.53125, dtype=float32), 'eval/episode_success': Array(382.53125, dtype=float32), 'eval/episode_success_easy': Array(771.28906, dtype=float32), 'eval/episode_success_any': Array(0.5390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.730543613433838, 'eval/sps': 4165.237088225308}
Time elapsed: 2.811 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 60 out of 100 complete. metrics: {'eval/walltime': 1868.9833796024323, 'training/sps': 7161.896689956082, 'training/walltime': 8413.357884168625, 'training/envsteps': 60567552.0, 'training/actor_loss': Array(4.372062, dtype=float32), 'training/alph_aloss': Array(-5.8651858e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.011246, dtype=float32), 'training/log_alpha': Array(-2.570616, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07162935, dtype=float32), 'training/sample_entropy': Array(-2.0008154, dtype=float32), 'eval/episode_reward': Array(381.39062, dtype=float32), 'eval/episode_success': Array(381.39062, dtype=float32), 'eval/episode_success_easy': Array(859.03906, dtype=float32), 'eval/episode_success_any': Array(0.5234375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 24.90971040725708, 'eval/sps': 5138.558333568947}
Time elapsed: 2.856 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 61 out of 100 complete. metrics: {'eval/walltime': 1900.4586961269379, 'training/sps': 7088.16635090775, 'training/walltime': 8552.189840316772, 'training/envsteps': 61551616.0, 'training/actor_loss': Array(4.35507, dtype=float32), 'training/alph_aloss': Array(-0.00012237, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.992817, dtype=float32), 'training/log_alpha': Array(-2.553179, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07378003, dtype=float32), 'training/sample_entropy': Array(-2.0016153, dtype=float32), 'eval/episode_reward': Array(278.53906, dtype=float32), 'eval/episode_success': Array(278.53906, dtype=float32), 'eval/episode_success_easy': Array(788.53906, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.475316524505615, 'eval/sps': 4066.678722685554}
Time elapsed: 2.904 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 62 out of 100 complete. metrics: {'eval/walltime': 1930.9826664924622, 'training/sps': 7191.660027988881, 'training/walltime': 8689.023894786835, 'training/envsteps': 62535680.0, 'training/actor_loss': Array(4.345275, dtype=float32), 'training/alph_aloss': Array(-6.4499975e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9854994, dtype=float32), 'training/log_alpha': Array(-2.5306067, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07547153, dtype=float32), 'training/sample_entropy': Array(-2.0008578, dtype=float32), 'eval/episode_reward': Array(309.0547, dtype=float32), 'eval/episode_success': Array(309.0547, dtype=float32), 'eval/episode_success_easy': Array(892.4375, dtype=float32), 'eval/episode_success_any': Array(0.5625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.523970365524292, 'eval/sps': 4193.425641133872}
Time elapsed: 2.950 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 63 out of 100 complete. metrics: {'eval/walltime': 1960.7521376609802, 'training/sps': 7117.083871401693, 'training/walltime': 8827.291760921478, 'training/envsteps': 63519744.0, 'training/actor_loss': Array(4.360261, dtype=float32), 'training/alph_aloss': Array(-1.7721062e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9992323, dtype=float32), 'training/log_alpha': Array(-2.527206, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07464998, dtype=float32), 'training/sample_entropy': Array(-2.0002718, dtype=float32), 'eval/episode_reward': Array(334.91406, dtype=float32), 'eval/episode_success': Array(334.91406, dtype=float32), 'eval/episode_success_easy': Array(787.78906, dtype=float32), 'eval/episode_success_any': Array(0.5625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.769471168518066, 'eval/sps': 4299.706880092754}
Time elapsed: 2.997 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 64 out of 100 complete. metrics: {'eval/walltime': 1991.075744152069, 'training/sps': 7195.50848239653, 'training/walltime': 8964.052630901337, 'training/envsteps': 64503808.0, 'training/actor_loss': Array(4.360947, dtype=float32), 'training/alph_aloss': Array(-6.975212e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9953933, dtype=float32), 'training/log_alpha': Array(-2.5089538, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07419778, dtype=float32), 'training/sample_entropy': Array(-2.0009024, dtype=float32), 'eval/episode_reward': Array(285.4297, dtype=float32), 'eval/episode_success': Array(285.4297, dtype=float32), 'eval/episode_success_easy': Array(834.1875, dtype=float32), 'eval/episode_success_any': Array(0.4140625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.323606491088867, 'eval/sps': 4221.1337901913175}
Time elapsed: 3.043 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 65 out of 100 complete. metrics: {'eval/walltime': 2023.1387853622437, 'training/sps': 7130.9136056078105, 'training/walltime': 9102.052339553833, 'training/envsteps': 65487872.0, 'training/actor_loss': Array(4.3506374, dtype=float32), 'training/alph_aloss': Array(-0.00018623, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9707875, dtype=float32), 'training/log_alpha': Array(-2.464531, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07489257, dtype=float32), 'training/sample_entropy': Array(-2.0022645, dtype=float32), 'eval/episode_reward': Array(452.26562, dtype=float32), 'eval/episode_success': Array(452.26562, dtype=float32), 'eval/episode_success_easy': Array(882.3047, dtype=float32), 'eval/episode_success_any': Array(0.6015625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.06304121017456, 'eval/sps': 3992.135342401075}
Time elapsed: 3.090 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 66 out of 100 complete. metrics: {'eval/walltime': 2050.446888923645, 'training/sps': 7219.44723988126, 'training/walltime': 9238.359728097916, 'training/envsteps': 66471936.0, 'training/actor_loss': Array(4.317734, dtype=float32), 'training/alph_aloss': Array(-0.00027902, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9265018, dtype=float32), 'training/log_alpha': Array(-2.416779, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07524956, dtype=float32), 'training/sample_entropy': Array(-2.0032022, dtype=float32), 'eval/episode_reward': Array(319.75, dtype=float32), 'eval/episode_success': Array(319.75, dtype=float32), 'eval/episode_success_easy': Array(825.7969, dtype=float32), 'eval/episode_success_any': Array(0.46875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.308103561401367, 'eval/sps': 4687.253353649998}
Time elapsed: 3.136 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 67 out of 100 complete. metrics: {'eval/walltime': 2074.329671382904, 'training/sps': 7111.030983523876, 'training/walltime': 9376.745287418365, 'training/envsteps': 67456000.0, 'training/actor_loss': Array(4.2828426, dtype=float32), 'training/alph_aloss': Array(-0.00010655, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.877622, dtype=float32), 'training/log_alpha': Array(-2.3890254, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07453063, dtype=float32), 'training/sample_entropy': Array(-2.00121, dtype=float32), 'eval/episode_reward': Array(338.21094, dtype=float32), 'eval/episode_success': Array(338.21094, dtype=float32), 'eval/episode_success_easy': Array(866.9219, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 23.882782459259033, 'eval/sps': 5359.509521905649}
Time elapsed: 3.181 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 68 out of 100 complete. metrics: {'eval/walltime': 2109.035693883896, 'training/sps': 7213.904902059868, 'training/walltime': 9513.157398939133, 'training/envsteps': 68440064.0, 'training/actor_loss': Array(4.247707, dtype=float32), 'training/alph_aloss': Array(-0.00016144, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8278875, dtype=float32), 'training/log_alpha': Array(-2.362435, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07346705, dtype=float32), 'training/sample_entropy': Array(-2.001759, dtype=float32), 'eval/episode_reward': Array(385.40625, dtype=float32), 'eval/episode_success': Array(385.40625, dtype=float32), 'eval/episode_success_easy': Array(843.9922, dtype=float32), 'eval/episode_success_any': Array(0.6015625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.70602250099182, 'eval/sps': 3688.1206999834694}
Time elapsed: 3.229 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 69 out of 100 complete. metrics: {'eval/walltime': 2139.114977836609, 'training/sps': 7122.398060334134, 'training/walltime': 9651.322100162506, 'training/envsteps': 69424128.0, 'training/actor_loss': Array(4.2078977, dtype=float32), 'training/alph_aloss': Array(-0.00010284, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.781315, dtype=float32), 'training/log_alpha': Array(-2.3356268, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.07229525, dtype=float32), 'training/sample_entropy': Array(-2.0011156, dtype=float32), 'eval/episode_reward': Array(351.35938, dtype=float32), 'eval/episode_success': Array(351.35938, dtype=float32), 'eval/episode_success_easy': Array(806.85156, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.079283952713013, 'eval/sps': 4255.420448213661}
Time elapsed: 3.275 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 70 out of 100 complete. metrics: {'eval/walltime': 2173.1154305934906, 'training/sps': 7215.389712417201, 'training/walltime': 9787.70614027977, 'training/envsteps': 70408192.0, 'training/actor_loss': Array(4.18855, dtype=float32), 'training/alph_aloss': Array(-4.977861e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7563486, dtype=float32), 'training/log_alpha': Array(-2.3218389, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06976022, dtype=float32), 'training/sample_entropy': Array(-2.000558, dtype=float32), 'eval/episode_reward': Array(393.26562, dtype=float32), 'eval/episode_success': Array(393.26562, dtype=float32), 'eval/episode_success_easy': Array(813.02344, dtype=float32), 'eval/episode_success_any': Array(0.5625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.000452756881714, 'eval/sps': 3764.655750770634}
Time elapsed: 3.323 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 71 out of 100 complete. metrics: {'eval/walltime': 2198.6657156944275, 'training/sps': 7122.852935876323, 'training/walltime': 9925.862018108368, 'training/envsteps': 71392256.0, 'training/actor_loss': Array(4.181313, dtype=float32), 'training/alph_aloss': Array(-0.0002027, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.738947, dtype=float32), 'training/log_alpha': Array(-2.2977986, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06783866, dtype=float32), 'training/sample_entropy': Array(-2.0020638, dtype=float32), 'eval/episode_reward': Array(414.5078, dtype=float32), 'eval/episode_success': Array(414.5078, dtype=float32), 'eval/episode_success_easy': Array(880.7578, dtype=float32), 'eval/episode_success_any': Array(0.53125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 25.55028510093689, 'eval/sps': 5009.728834505508}
Time elapsed: 3.368 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 72 out of 100 complete. metrics: {'eval/walltime': 2230.759745836258, 'training/sps': 7203.430531397284, 'training/walltime': 10062.472483873367, 'training/envsteps': 72376320.0, 'training/actor_loss': Array(4.177265, dtype=float32), 'training/alph_aloss': Array(-0.00013729, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.725266, dtype=float32), 'training/log_alpha': Array(-2.257098, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06587118, dtype=float32), 'training/sample_entropy': Array(-2.0013793, dtype=float32), 'eval/episode_reward': Array(326.89844, dtype=float32), 'eval/episode_success': Array(326.89844, dtype=float32), 'eval/episode_success_easy': Array(910.83594, dtype=float32), 'eval/episode_success_any': Array(0.53125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.094030141830444, 'eval/sps': 3988.280668845277}
Time elapsed: 3.415 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 73 out of 100 complete. metrics: {'eval/walltime': 2263.563128232956, 'training/sps': 7213.087999990661, 'training/walltime': 10198.900044441223, 'training/envsteps': 73360384.0, 'training/actor_loss': Array(4.1891675, dtype=float32), 'training/alph_aloss': Array(-0.00023392, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7303696, dtype=float32), 'training/log_alpha': Array(-2.2327886, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06366207, dtype=float32), 'training/sample_entropy': Array(-2.0022469, dtype=float32), 'eval/episode_reward': Array(288.7578, dtype=float32), 'eval/episode_success': Array(288.7578, dtype=float32), 'eval/episode_success_easy': Array(900., dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.803382396698, 'eval/sps': 3902.0366391511056}
Time elapsed: 3.462 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 74 out of 100 complete. metrics: {'eval/walltime': 2295.499582052231, 'training/sps': 7211.046402835372, 'training/walltime': 10335.366230487823, 'training/envsteps': 74344448.0, 'training/actor_loss': Array(4.2201834, dtype=float32), 'training/alph_aloss': Array(1.1273508e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7494917, dtype=float32), 'training/log_alpha': Array(-2.2126, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06131904, dtype=float32), 'training/sample_entropy': Array(-1.9999453, dtype=float32), 'eval/episode_reward': Array(267.2578, dtype=float32), 'eval/episode_success': Array(267.2578, dtype=float32), 'eval/episode_success_easy': Array(866.4219, dtype=float32), 'eval/episode_success_any': Array(0.4140625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.936453819274902, 'eval/sps': 4007.959077871914}
Time elapsed: 3.509 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 75 out of 100 complete. metrics: {'eval/walltime': 2330.8948805332184, 'training/sps': 7234.427499637394, 'training/walltime': 10471.391368627548, 'training/envsteps': 75328512.0, 'training/actor_loss': Array(4.2567043, dtype=float32), 'training/alph_aloss': Array(-0.00016667, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7772117, dtype=float32), 'training/log_alpha': Array(-2.20426, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05935395, dtype=float32), 'training/sample_entropy': Array(-2.0015657, dtype=float32), 'eval/episode_reward': Array(378.625, dtype=float32), 'eval/episode_success': Array(378.625, dtype=float32), 'eval/episode_success_easy': Array(942.28125, dtype=float32), 'eval/episode_success_any': Array(0.5390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 35.39529848098755, 'eval/sps': 3616.2994943736585}
Time elapsed: 3.556 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 76 out of 100 complete. metrics: {'eval/walltime': 2352.797082901001, 'training/sps': 7229.059594777535, 'training/walltime': 10607.517511606216, 'training/envsteps': 76312576.0, 'training/actor_loss': Array(4.273683, dtype=float32), 'training/alph_aloss': Array(-3.4293535e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.794592, dtype=float32), 'training/log_alpha': Array(-2.205287, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05789441, dtype=float32), 'training/sample_entropy': Array(-2.000356, dtype=float32), 'eval/episode_reward': Array(344.2578, dtype=float32), 'eval/episode_success': Array(344.2578, dtype=float32), 'eval/episode_success_easy': Array(880.22656, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 21.902202367782593, 'eval/sps': 5844.161141907981}
Time elapsed: 3.600 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 77 out of 100 complete. metrics: {'eval/walltime': 2382.2619454860687, 'training/sps': 7210.779693240015, 'training/walltime': 10743.988745212555, 'training/envsteps': 77296640.0, 'training/actor_loss': Array(4.2695913, dtype=float32), 'training/alph_aloss': Array(7.679985e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7877007, dtype=float32), 'training/log_alpha': Array(-2.2005336, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05811568, dtype=float32), 'training/sample_entropy': Array(-1.9993546, dtype=float32), 'eval/episode_reward': Array(264.71094, dtype=float32), 'eval/episode_success': Array(264.71094, dtype=float32), 'eval/episode_success_easy': Array(894.8828, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.46486258506775, 'eval/sps': 4344.157371528624}
Time elapsed: 3.646 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 78 out of 100 complete. metrics: {'eval/walltime': 2414.562744617462, 'training/sps': 7234.389510046484, 'training/walltime': 10880.014597654343, 'training/envsteps': 78280704.0, 'training/actor_loss': Array(4.2708273, dtype=float32), 'training/alph_aloss': Array(0.00018468, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.786323, dtype=float32), 'training/log_alpha': Array(-2.2116725, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0574397, dtype=float32), 'training/sample_entropy': Array(-1.998354, dtype=float32), 'eval/episode_reward': Array(352.35156, dtype=float32), 'eval/episode_success': Array(352.35156, dtype=float32), 'eval/episode_success_easy': Array(873.7656, dtype=float32), 'eval/episode_success_any': Array(0.4453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.30079913139343, 'eval/sps': 3962.7502551661537}
Time elapsed: 3.693 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 79 out of 100 complete. metrics: {'eval/walltime': 2447.550950527191, 'training/sps': 7136.343777735649, 'training/walltime': 11017.909299850464, 'training/envsteps': 79264768.0, 'training/actor_loss': Array(4.271759, dtype=float32), 'training/alph_aloss': Array(0.00012643, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7829247, dtype=float32), 'training/log_alpha': Array(-2.23629, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05694795, dtype=float32), 'training/sample_entropy': Array(-1.9988648, dtype=float32), 'eval/episode_reward': Array(339.39062, dtype=float32), 'eval/episode_success': Array(339.39062, dtype=float32), 'eval/episode_success_easy': Array(900.5078, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.988205909729004, 'eval/sps': 3880.174640302271}
Time elapsed: 3.741 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 80 out of 100 complete. metrics: {'eval/walltime': 2480.9031212329865, 'training/sps': 7210.706351874957, 'training/walltime': 11154.38192152977, 'training/envsteps': 80248832.0, 'training/actor_loss': Array(4.2668996, dtype=float32), 'training/alph_aloss': Array(0.00021634, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.779347, dtype=float32), 'training/log_alpha': Array(-2.2593076, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05613769, dtype=float32), 'training/sample_entropy': Array(-1.9979672, dtype=float32), 'eval/episode_reward': Array(347.16406, dtype=float32), 'eval/episode_success': Array(347.16406, dtype=float32), 'eval/episode_success_easy': Array(844.3281, dtype=float32), 'eval/episode_success_any': Array(0.5078125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.35217070579529, 'eval/sps': 3837.8311603495918}
Time elapsed: 3.788 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 81 out of 100 complete. metrics: {'eval/walltime': 2511.6176698207855, 'training/sps': 7117.013405371284, 'training/walltime': 11292.651156663895, 'training/envsteps': 81232896.0, 'training/actor_loss': Array(4.260702, dtype=float32), 'training/alph_aloss': Array(-3.6493115e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.777082, dtype=float32), 'training/log_alpha': Array(-2.2667565, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05591097, dtype=float32), 'training/sample_entropy': Array(-2.0004034, dtype=float32), 'eval/episode_reward': Array(259.35938, dtype=float32), 'eval/episode_success': Array(259.35938, dtype=float32), 'eval/episode_success_easy': Array(804.2969, dtype=float32), 'eval/episode_success_any': Array(0.4140625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.714548587799072, 'eval/sps': 4167.40619300022}
Time elapsed: 3.835 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 82 out of 100 complete. metrics: {'eval/walltime': 2542.5229659080505, 'training/sps': 7211.8689918983555, 'training/walltime': 11429.10177731514, 'training/envsteps': 82216960.0, 'training/actor_loss': Array(4.2651963, dtype=float32), 'training/alph_aloss': Array(0.00036438, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.7975335, dtype=float32), 'training/log_alpha': Array(-2.3053138, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05414237, dtype=float32), 'training/sample_entropy': Array(-1.9964055, dtype=float32), 'eval/episode_reward': Array(337.375, dtype=float32), 'eval/episode_success': Array(337.375, dtype=float32), 'eval/episode_success_easy': Array(866.5, dtype=float32), 'eval/episode_success_any': Array(0.4375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.905296087265015, 'eval/sps': 4141.684960356821}
Time elapsed: 3.881 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 83 out of 100 complete. metrics: {'eval/walltime': 2575.5665187835693, 'training/sps': 7125.39553407789, 'training/walltime': 11567.208356142044, 'training/envsteps': 83201024.0, 'training/actor_loss': Array(4.2815685, dtype=float32), 'training/alph_aloss': Array(0.00023539, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8264966, dtype=float32), 'training/log_alpha': Array(-2.3520985, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05305298, dtype=float32), 'training/sample_entropy': Array(-1.9975791, dtype=float32), 'eval/episode_reward': Array(286.8672, dtype=float32), 'eval/episode_success': Array(286.8672, dtype=float32), 'eval/episode_success_easy': Array(806.78125, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.0435528755188, 'eval/sps': 3873.675463476938}
Time elapsed: 3.929 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 84 out of 100 complete. metrics: {'eval/walltime': 2603.213131904602, 'training/sps': 7203.554641782863, 'training/walltime': 11703.81646823883, 'training/envsteps': 84185088.0, 'training/actor_loss': Array(4.301658, dtype=float32), 'training/alph_aloss': Array(0.00025539, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8591113, dtype=float32), 'training/log_alpha': Array(-2.4014578, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05246792, dtype=float32), 'training/sample_entropy': Array(-1.9972484, dtype=float32), 'eval/episode_reward': Array(376.8828, dtype=float32), 'eval/episode_success': Array(376.8828, dtype=float32), 'eval/episode_success_easy': Array(856.9922, dtype=float32), 'eval/episode_success_any': Array(0.5390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.646613121032715, 'eval/sps': 4629.861872759431}
Time elapsed: 3.974 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 85 out of 100 complete. metrics: {'eval/walltime': 2635.6278760433197, 'training/sps': 7120.14174956087, 'training/walltime': 11842.02495265007, 'training/envsteps': 85169152.0, 'training/actor_loss': Array(4.3101625, dtype=float32), 'training/alph_aloss': Array(4.713765e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.882202, dtype=float32), 'training/log_alpha': Array(-2.4333706, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05255822, dtype=float32), 'training/sample_entropy': Array(-1.999516, dtype=float32), 'eval/episode_reward': Array(349.75, dtype=float32), 'eval/episode_success': Array(349.75, dtype=float32), 'eval/episode_success_easy': Array(843.16406, dtype=float32), 'eval/episode_success_any': Array(0.46875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.41474413871765, 'eval/sps': 3948.8203100486903}
Time elapsed: 4.022 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 86 out of 100 complete. metrics: {'eval/walltime': 2660.9603304862976, 'training/sps': 7232.137970119882, 'training/walltime': 11978.093153238297, 'training/envsteps': 86153216.0, 'training/actor_loss': Array(4.309816, dtype=float32), 'training/alph_aloss': Array(2.693611e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8918085, dtype=float32), 'training/log_alpha': Array(-2.4222844, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05378681, dtype=float32), 'training/sample_entropy': Array(-1.9997442, dtype=float32), 'eval/episode_reward': Array(397.3203, dtype=float32), 'eval/episode_success': Array(397.3203, dtype=float32), 'eval/episode_success_easy': Array(882.1953, dtype=float32), 'eval/episode_success_any': Array(0.515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 25.332454442977905, 'eval/sps': 5052.806876180183}
Time elapsed: 4.067 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 87 out of 100 complete. metrics: {'eval/walltime': 2689.388531446457, 'training/sps': 7142.231251240428, 'training/walltime': 12115.87418627739, 'training/envsteps': 87137280.0, 'training/actor_loss': Array(4.2990556, dtype=float32), 'training/alph_aloss': Array(5.6054287e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.880873, dtype=float32), 'training/log_alpha': Array(-2.4279447, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05619741, dtype=float32), 'training/sample_entropy': Array(-1.9994037, dtype=float32), 'eval/episode_reward': Array(338.89844, dtype=float32), 'eval/episode_success': Array(338.89844, dtype=float32), 'eval/episode_success_easy': Array(844.89844, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.4282009601593, 'eval/sps': 4502.571238306131}
Time elapsed: 4.113 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 88 out of 100 complete. metrics: {'eval/walltime': 2716.790966272354, 'training/sps': 7207.431773880982, 'training/walltime': 12252.408812046051, 'training/envsteps': 88121344.0, 'training/actor_loss': Array(4.2842965, dtype=float32), 'training/alph_aloss': Array(8.8254e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.867807, dtype=float32), 'training/log_alpha': Array(-2.4437754, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05865503, dtype=float32), 'training/sample_entropy': Array(-1.9999429, dtype=float32), 'eval/episode_reward': Array(223.00781, dtype=float32), 'eval/episode_success': Array(223.00781, dtype=float32), 'eval/episode_success_easy': Array(791.4844, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.402434825897217, 'eval/sps': 4671.117760638958}
Time elapsed: 4.158 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 89 out of 100 complete. metrics: {'eval/walltime': 2744.4808807373047, 'training/sps': 7142.276881089615, 'training/walltime': 12390.18896484375, 'training/envsteps': 89105408.0, 'training/actor_loss': Array(4.285305, dtype=float32), 'training/alph_aloss': Array(3.756929e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8745008, dtype=float32), 'training/log_alpha': Array(-2.4631882, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05963407, dtype=float32), 'training/sample_entropy': Array(-1.9996123, dtype=float32), 'eval/episode_reward': Array(305.1875, dtype=float32), 'eval/episode_success': Array(305.1875, dtype=float32), 'eval/episode_success_easy': Array(811.7344, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.68991446495056, 'eval/sps': 4622.621718894086}
Time elapsed: 4.204 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 90 out of 100 complete. metrics: {'eval/walltime': 2777.298147916794, 'training/sps': 7206.738569133053, 'training/walltime': 12526.736723661423, 'training/envsteps': 90089472.0, 'training/actor_loss': Array(4.3019724, dtype=float32), 'training/alph_aloss': Array(4.6513756e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.8911667, dtype=float32), 'training/log_alpha': Array(-2.4629056, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05975899, dtype=float32), 'training/sample_entropy': Array(-1.9994997, dtype=float32), 'eval/episode_reward': Array(406.10938, dtype=float32), 'eval/episode_success': Array(406.10938, dtype=float32), 'eval/episode_success_easy': Array(856.03906, dtype=float32), 'eval/episode_success_any': Array(0.5234375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.817267179489136, 'eval/sps': 3900.3857115805267}
Time elapsed: 4.251 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 91 out of 100 complete. metrics: {'eval/walltime': 2808.4120314121246, 'training/sps': 7132.288931552209, 'training/walltime': 12664.70982170105, 'training/envsteps': 91073536.0, 'training/actor_loss': Array(4.320646, dtype=float32), 'training/alph_aloss': Array(-5.4736134e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.918139, dtype=float32), 'training/log_alpha': Array(-2.467888, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05941526, dtype=float32), 'training/sample_entropy': Array(-2.0006862, dtype=float32), 'eval/episode_reward': Array(305.64062, dtype=float32), 'eval/episode_success': Array(305.64062, dtype=float32), 'eval/episode_success_easy': Array(803.6328, dtype=float32), 'eval/episode_success_any': Array(0.46875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.11388349533081, 'eval/sps': 4113.919113286153}
Time elapsed: 4.298 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 92 out of 100 complete. metrics: {'eval/walltime': 2834.898916244507, 'training/sps': 7184.776709322858, 'training/walltime': 12801.674968957901, 'training/envsteps': 92057600.0, 'training/actor_loss': Array(4.3510876, dtype=float32), 'training/alph_aloss': Array(6.653997e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.9593425, dtype=float32), 'training/log_alpha': Array(-2.460932, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05955094, dtype=float32), 'training/sample_entropy': Array(-1.9992687, dtype=float32), 'eval/episode_reward': Array(289.64062, dtype=float32), 'eval/episode_success': Array(289.64062, dtype=float32), 'eval/episode_success_easy': Array(776.1406, dtype=float32), 'eval/episode_success_any': Array(0.3828125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 26.486884832382202, 'eval/sps': 4832.580381197203}
Time elapsed: 4.344 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 93 out of 100 complete. metrics: {'eval/walltime': 2863.478883743286, 'training/sps': 7215.071462091434, 'training/walltime': 12938.065024852753, 'training/envsteps': 93041664.0, 'training/actor_loss': Array(4.420803, dtype=float32), 'training/alph_aloss': Array(6.686849e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.045308, dtype=float32), 'training/log_alpha': Array(-2.483749, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0584515, dtype=float32), 'training/sample_entropy': Array(-1.9992512, dtype=float32), 'eval/episode_reward': Array(389.5625, dtype=float32), 'eval/episode_success': Array(389.5625, dtype=float32), 'eval/episode_success_easy': Array(834.3906, dtype=float32), 'eval/episode_success_any': Array(0.515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.579967498779297, 'eval/sps': 4478.661496219935}
Time elapsed: 4.390 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 94 out of 100 complete. metrics: {'eval/walltime': 2896.986397266388, 'training/sps': 7208.000869249791, 'training/walltime': 13074.588870763779, 'training/envsteps': 94025728.0, 'training/actor_loss': Array(4.4774604, dtype=float32), 'training/alph_aloss': Array(0.00012867, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.1090064, dtype=float32), 'training/log_alpha': Array(-2.5087214, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05867376, dtype=float32), 'training/sample_entropy': Array(-1.9984673, dtype=float32), 'eval/episode_reward': Array(290.3828, dtype=float32), 'eval/episode_success': Array(290.3828, dtype=float32), 'eval/episode_success_easy': Array(769.22656, dtype=float32), 'eval/episode_success_any': Array(0.5, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.50751352310181, 'eval/sps': 3820.0387477796644}
Time elapsed: 4.437 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 95 out of 100 complete. metrics: {'eval/walltime': 2926.870986223221, 'training/sps': 7198.1319596322055, 'training/walltime': 13211.299896001816, 'training/envsteps': 95009792.0, 'training/actor_loss': Array(4.52992, dtype=float32), 'training/alph_aloss': Array(6.5772764e-07, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.1710563, dtype=float32), 'training/log_alpha': Array(-2.526094, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05884816, dtype=float32), 'training/sample_entropy': Array(-2.000038, dtype=float32), 'eval/episode_reward': Array(340.66406, dtype=float32), 'eval/episode_success': Array(340.66406, dtype=float32), 'eval/episode_success_easy': Array(883.3828, dtype=float32), 'eval/episode_success_any': Array(0.5234375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.884588956832886, 'eval/sps': 4283.144070841696}
Time elapsed: 4.483 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 96 out of 100 complete. metrics: {'eval/walltime': 2956.1944794654846, 'training/sps': 7227.808286607628, 'training/walltime': 13347.449605703354, 'training/envsteps': 95993856.0, 'training/actor_loss': Array(4.567178, dtype=float32), 'training/alph_aloss': Array(2.9613011e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.223877, dtype=float32), 'training/log_alpha': Array(-2.5344265, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.05940407, dtype=float32), 'training/sample_entropy': Array(-1.9996791, dtype=float32), 'eval/episode_reward': Array(311.0078, dtype=float32), 'eval/episode_success': Array(311.0078, dtype=float32), 'eval/episode_success_easy': Array(892.21875, dtype=float32), 'eval/episode_success_any': Array(0.59375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.323493242263794, 'eval/sps': 4365.100670049579}
Time elapsed: 4.529 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 97 out of 100 complete. metrics: {'eval/walltime': 2985.5961787700653, 'training/sps': 7217.7033828197555, 'training/walltime': 13483.789927244186, 'training/envsteps': 96977920.0, 'training/actor_loss': Array(4.579387, dtype=float32), 'training/alph_aloss': Array(2.5671434e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.2463017, dtype=float32), 'training/log_alpha': Array(-2.536014, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06153412, dtype=float32), 'training/sample_entropy': Array(-2.000018, dtype=float32), 'eval/episode_reward': Array(333.8203, dtype=float32), 'eval/episode_success': Array(333.8203, dtype=float32), 'eval/episode_success_easy': Array(907.7969, dtype=float32), 'eval/episode_success_any': Array(0.5, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.40169930458069, 'eval/sps': 4353.489867167576}
Time elapsed: 4.575 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 98 out of 100 complete. metrics: {'eval/walltime': 3014.2380559444427, 'training/sps': 7210.909348097311, 'training/walltime': 13620.258707046509, 'training/envsteps': 97961984.0, 'training/actor_loss': Array(4.544774, dtype=float32), 'training/alph_aloss': Array(-7.431249e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.2121015, dtype=float32), 'training/log_alpha': Array(-2.5170557, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06447802, dtype=float32), 'training/sample_entropy': Array(-2.0009704, dtype=float32), 'eval/episode_reward': Array(276.6172, dtype=float32), 'eval/episode_success': Array(276.6172, dtype=float32), 'eval/episode_success_easy': Array(884.28906, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.64187717437744, 'eval/sps': 4468.98082903961}
Time elapsed: 4.621 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 99 out of 100 complete. metrics: {'eval/walltime': 3039.652125120163, 'training/sps': 7225.094599389738, 'training/walltime': 13756.459553480148, 'training/envsteps': 98946048.0, 'training/actor_loss': Array(4.505147, dtype=float32), 'training/alph_aloss': Array(-0.00013465, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.1666017, dtype=float32), 'training/log_alpha': Array(-2.482173, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.06660676, dtype=float32), 'training/sample_entropy': Array(-2.0016565, dtype=float32), 'eval/episode_reward': Array(314.5625, dtype=float32), 'eval/episode_success': Array(314.5625, dtype=float32), 'eval/episode_success_easy': Array(836.53125, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 25.414069175720215, 'eval/sps': 5036.580293969101}
Time elapsed: 4.666 hours
wandb: 
wandb: Run history:
wandb:       eval/avg_episode_length ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           eval/episode_reward ▅▆▅▆▇█▆█▄▅▃█▆▆▆▇▆▅▅▄▅▃▆▃▆▄▄▆▆▃▄▅▂▃▆▁▃▆▄▄
wandb:          eval/episode_success ▅▆▅▆▇█▆█▄▅▃█▆▆▆▇▆▅▅▄▅▃▆▃▆▄▄▆▆▃▄▅▂▃▆▁▃▆▄▄
wandb:      eval/episode_success_any ▃▅▁▂▄▅▃▆▂▄▂▅▅▆▄█▄▄▄▄▆▄▇▄▅▇▄█▆▄▄▃▂▂▅▁▄▅█▃
wandb:     eval/episode_success_easy ▅▁▅▆▇▆▃▇▄▅▅▇▇▄▃▅▃▃▄▄▆▃▆▆▇▅▆▆▇█▇▇▅▅▇▅▅▆█▆
wandb:          eval/epoch_eval_time █▄▃▃▂▃▃▄▄▃▂▄▃▁▄▄▃▃▃▁▄▃▄▂▂▃▃▄▂▄▁▄▃▄▂▃▃▃▃▂
wandb:                      eval/sps ▁▃▄▅▆▄▅▄▄▄▆▃▄▇▃▃▅▅▄█▃▄▃▆▆▄▅▃▅▄▇▄▄▄▆▅▄▅▄▆
wandb:                 eval/walltime ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:           training/actor_loss █▄▃▃▃▂▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃
wandb:           training/alph_aloss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  training/buffer_current_size ▁▅██████████████████████████████████████
wandb: training/categorical_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          training/critic_loss █▃▂▃▂▂▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▃▃▃
wandb:             training/envsteps ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            training/log_alpha █▁▄▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▂▁▂▂▃▃▃▃▃▃▃▂▂▂▂▂▂
wandb:           training/logits_neg ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           training/logits_pos ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            training/logsumexp █▃▁▂▂▂▂▁▁▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▃▃▃▃▄▄▄▄▄▅▄▄▄▄▄▄
wandb:       training/sample_entropy █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  training/sps ▁████▇▇▇▇▇▆▆▇▆▆▇▇▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:             training/walltime ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:       eval/avg_episode_length 1000.0
wandb:           eval/episode_reward 314.5625
wandb:          eval/episode_success 314.5625
wandb:      eval/episode_success_any 0.45312
wandb:     eval/episode_success_easy 836.53125
wandb:          eval/epoch_eval_time 25.41407
wandb:                      eval/sps 5036.58029
wandb:                 eval/walltime 3039.65213
wandb:           training/actor_loss 4.50515
wandb:           training/alph_aloss -0.00013
wandb:  training/buffer_current_size 10000.0
wandb: training/categorical_accuracy 0.0
wandb:          training/critic_loss 5.1666
wandb:             training/envsteps 98946048.0
wandb:            training/log_alpha -2.48217
wandb:           training/logits_neg 0.0
wandb:           training/logits_pos 0.0
wandb:            training/logsumexp -0.06661
wandb:       training/sample_entropy -2.00166
wandb:                  training/sps 7225.0946
wandb:             training/walltime 13756.45955
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync ./wandb/offline-run-20241104_011514-h9njpyqj
wandb: Find logs at: ./wandb/offline-run-20241104_011514-h9njpyqj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
