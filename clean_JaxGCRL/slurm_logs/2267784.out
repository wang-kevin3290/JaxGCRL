Waiting for _ hour before starting...
Starting job execution...
-rwxr-xr-x 1 kw6487 student 37329 Nov  4 01:03 /scratch/network/kw6487/JaxGCRL/clean_JaxGCRL/train_crl_jax_brax.py
Arguments:
exp_name: train
seed: 775
torch_deterministic: True
cuda: True
track: True
wandb_project_name: clean_JaxGCRL_test
wandb_entity: wang-kevin3290-princeton-university
wandb_mode: offline
wandb_dir: .
wandb_group: .
capture_video: True
checkpoint: False
env_id: arm_reach
episode_length: 1000
obs_dim: 0
goal_start_idx: 0
goal_end_idx: 0
total_env_steps: 100000000
num_epochs: 100
num_envs: 512
num_eval_envs: 128
actor_lr: 0.0003
critic_lr: 0.0003
alpha_lr: 0.0003
batch_size: 256
gamma: 0.99
logsumexp_penalty_coeff: 0.1
critic_batch_size_multiplier: 1.0
actor_batch_size_multiplier: 1.0
max_replay_size: 10000
min_replay_size: 1000
unroll_length: 62
same_network_width: 0
network_width: 256
critic_network_width: 256
actor_network_width: 256
num_episodes_per_env: 1
training_steps_multiplier: 1
use_all_batches: 0
num_sgd_batches_per_training_step: 200
mrn: 0
memory_bank: 0
memory_bank_size: 256
batchdiv2: 0
env_steps_per_actor_step: 0
num_prefill_env_steps: 0
num_prefill_actor_steps: 0
num_training_steps_per_epoch: 0


env_steps_per_actor_step: 31744
num_prefill_env_steps: 512000
num_prefill_actor_steps: 17.0
num_training_steps_per_epoch: 31
run_name: arm_reach_256_critbx:1.0_actbx:1.0_batchdiv2:0_100000000_nenvs:512_criticwidth:256_actorwidth:256_epspenv:1_trainmult:1_mrn:0_memorybank:0_sgdbatchesptrainstep:200_useallbatches:0_775
wandb: Tracking run with wandb version 0.17.9
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
obs_size: 16, action_size: 4
x.shape: (1, 16)
data_size: 24
x.shape: (512, 16)
starting training....
x.shape: (512, 16)
buffer_state.data[:, envs_idxs, :].shape: (10000, 512, 24)
transitions.observation.shape (after 1 episodes per env): (512, 1000, 16)
transitions.observation.shape (after flatten_crl_fn): (512, 999, 16)
transitions.observation.shape (after first reshape): (511488, 16)
transitions.observation.shape (after ensuring divisibility by batch_size): (511488, 16)
transitions.observation.shape (after processing): (1998, 256, 16)
transitions.observation.shape (after 0, selecting 200 batches): (200, 256, 16)
x.shape: (256, 16)
x.shape: (128, 16)
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 0 out of 100 complete. metrics: {'eval/walltime': 35.958423137664795, 'training/sps': 8291.752923751623, 'training/walltime': 118.67985081672668, 'training/envsteps': 1523712.0, 'training/actor_loss': Array(4.250591, dtype=float32), 'training/alph_aloss': Array(2.2096398, dtype=float32), 'training/buffer_current_size': Array(2976., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.3587394, dtype=float32), 'training/log_alpha': Array(-0.7765852, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.00035979, dtype=float32), 'training/sample_entropy': Array(2.3325179, dtype=float32), 'eval/episode_reward': Array(0.078125, dtype=float32), 'eval/episode_success': Array(0.078125, dtype=float32), 'eval/episode_success_easy': Array(360.03125, dtype=float32), 'eval/episode_success_any': Array(0.046875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 35.958423137664795, 'eval/sps': 3559.6666602970663}
Time elapsed: 0.043 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 1 out of 100 complete. metrics: {'eval/walltime': 73.44083547592163, 'training/sps': 9645.142937620296, 'training/walltime': 220.7067472934723, 'training/envsteps': 2507776.0, 'training/actor_loss': Array(5.013366, dtype=float32), 'training/alph_aloss': Array(0.49165806, dtype=float32), 'training/buffer_current_size': Array(4898., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.3581758, dtype=float32), 'training/log_alpha': Array(-2.1682599, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.00023198, dtype=float32), 'training/sample_entropy': Array(1.9126554, dtype=float32), 'eval/episode_reward': Array(67.390625, dtype=float32), 'eval/episode_success': Array(67.390625, dtype=float32), 'eval/episode_success_easy': Array(530.2578, dtype=float32), 'eval/episode_success_any': Array(0.1796875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 37.482412338256836, 'eval/sps': 3414.934952555212}
Time elapsed: 0.082 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 2 out of 100 complete. metrics: {'eval/walltime': 105.42421698570251, 'training/sps': 10376.539212484542, 'training/walltime': 315.54221987724304, 'training/envsteps': 3491840.0, 'training/actor_loss': Array(4.8975763, dtype=float32), 'training/alph_aloss': Array(0.07025077, dtype=float32), 'training/buffer_current_size': Array(6820., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(5.2006884, dtype=float32), 'training/log_alpha': Array(-3.3580325, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.01486302, dtype=float32), 'training/sample_entropy': Array(-0.31920263, dtype=float32), 'eval/episode_reward': Array(354.76562, dtype=float32), 'eval/episode_success': Array(354.76562, dtype=float32), 'eval/episode_success_easy': Array(889.34375, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.983381509780884, 'eval/sps': 4002.0783906434704}
Time elapsed: 0.117 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 3 out of 100 complete. metrics: {'eval/walltime': 127.48407077789307, 'training/sps': 11591.64126478052, 'training/walltime': 400.43649649620056, 'training/envsteps': 4475904.0, 'training/actor_loss': Array(3.971641, dtype=float32), 'training/alph_aloss': Array(-0.00439098, dtype=float32), 'training/buffer_current_size': Array(8742., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.360496, dtype=float32), 'training/log_alpha': Array(-3.42172, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09012119, dtype=float32), 'training/sample_entropy': Array(-2.1338053, dtype=float32), 'eval/episode_reward': Array(435.125, dtype=float32), 'eval/episode_success': Array(435.125, dtype=float32), 'eval/episode_success_easy': Array(913.1719, dtype=float32), 'eval/episode_success_any': Array(0.5234375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 22.05985379219055, 'eval/sps': 5802.395664349938}
Time elapsed: 0.147 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 4 out of 100 complete. metrics: {'eval/walltime': 159.01687955856323, 'training/sps': 11588.805286156858, 'training/walltime': 485.35154819488525, 'training/envsteps': 5459968.0, 'training/actor_loss': Array(3.4236894, dtype=float32), 'training/alph_aloss': Array(-0.00643496, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.744787, dtype=float32), 'training/log_alpha': Array(-2.76052, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1619717, dtype=float32), 'training/sample_entropy': Array(-2.1013298, dtype=float32), 'eval/episode_reward': Array(469.1328, dtype=float32), 'eval/episode_success': Array(469.1328, dtype=float32), 'eval/episode_success_easy': Array(928.5, dtype=float32), 'eval/episode_success_any': Array(0.5625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.532808780670166, 'eval/sps': 4059.2641426368873}
Time elapsed: 0.179 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 5 out of 100 complete. metrics: {'eval/walltime': 193.19981217384338, 'training/sps': 11403.109462572993, 'training/walltime': 571.6494131088257, 'training/envsteps': 6444032.0, 'training/actor_loss': Array(3.0450766, dtype=float32), 'training/alph_aloss': Array(-0.01282762, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.2343843, dtype=float32), 'training/log_alpha': Array(-2.1877017, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.20509543, dtype=float32), 'training/sample_entropy': Array(-2.1167684, dtype=float32), 'eval/episode_reward': Array(482.5078, dtype=float32), 'eval/episode_success': Array(482.5078, dtype=float32), 'eval/episode_success_easy': Array(866.6953, dtype=float32), 'eval/episode_success_any': Array(0.53125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.18293261528015, 'eval/sps': 3744.5587668151848}
Time elapsed: 0.212 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 6 out of 100 complete. metrics: {'eval/walltime': 224.72321105003357, 'training/sps': 11266.862008133292, 'training/walltime': 658.9908573627472, 'training/envsteps': 7428096.0, 'training/actor_loss': Array(2.9217856, dtype=float32), 'training/alph_aloss': Array(-0.00954139, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(2.9555275, dtype=float32), 'training/log_alpha': Array(-1.7963578, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.23113105, dtype=float32), 'training/sample_entropy': Array(-2.0584536, dtype=float32), 'eval/episode_reward': Array(366.0547, dtype=float32), 'eval/episode_success': Array(366.0547, dtype=float32), 'eval/episode_success_easy': Array(664.1328, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.523398876190186, 'eval/sps': 4060.4758548634545}
Time elapsed: 0.246 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 7 out of 100 complete. metrics: {'eval/walltime': 256.12501192092896, 'training/sps': 11017.751366292641, 'training/walltime': 748.3070859909058, 'training/envsteps': 8412160.0, 'training/actor_loss': Array(3.0394073, dtype=float32), 'training/alph_aloss': Array(0.00131246, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(2.9814744, dtype=float32), 'training/log_alpha': Array(-1.6583862, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.24644576, dtype=float32), 'training/sample_entropy': Array(-1.993151, dtype=float32), 'eval/episode_reward': Array(257.16406, dtype=float32), 'eval/episode_success': Array(257.16406, dtype=float32), 'eval/episode_success_easy': Array(547.58594, dtype=float32), 'eval/episode_success_any': Array(0.3515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.401800870895386, 'eval/sps': 4076.1993404854757}
Time elapsed: 0.279 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 8 out of 100 complete. metrics: {'eval/walltime': 288.7132182121277, 'training/sps': 11053.348473646978, 'training/walltime': 837.3356733322144, 'training/envsteps': 9396224.0, 'training/actor_loss': Array(3.1009502, dtype=float32), 'training/alph_aloss': Array(0.00889762, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.1816974, dtype=float32), 'training/log_alpha': Array(-1.8198863, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.21227837, dtype=float32), 'training/sample_entropy': Array(-1.944819, dtype=float32), 'eval/episode_reward': Array(319.65625, dtype=float32), 'eval/episode_success': Array(319.65625, dtype=float32), 'eval/episode_success_easy': Array(594.77344, dtype=float32), 'eval/episode_success_any': Array(0.4375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.58820629119873, 'eval/sps': 3927.8013296046197}
Time elapsed: 0.313 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 9 out of 100 complete. metrics: {'eval/walltime': 320.1651396751404, 'training/sps': 11139.383802863742, 'training/walltime': 925.6766459941864, 'training/envsteps': 10380288.0, 'training/actor_loss': Array(3.1702738, dtype=float32), 'training/alph_aloss': Array(0.00950069, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.4718196, dtype=float32), 'training/log_alpha': Array(-2.1023493, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.18184413, dtype=float32), 'training/sample_entropy': Array(-1.9208229, dtype=float32), 'eval/episode_reward': Array(340.04688, dtype=float32), 'eval/episode_success': Array(340.04688, dtype=float32), 'eval/episode_success_easy': Array(617.8203, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.451921463012695, 'eval/sps': 4069.7036634320534}
Time elapsed: 0.346 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 10 out of 100 complete. metrics: {'eval/walltime': 352.5481986999512, 'training/sps': 11170.388604770453, 'training/walltime': 1013.7724173069, 'training/envsteps': 11364352.0, 'training/actor_loss': Array(3.337635, dtype=float32), 'training/alph_aloss': Array(0.00493581, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8045084, dtype=float32), 'training/log_alpha': Array(-2.4075472, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.15141219, dtype=float32), 'training/sample_entropy': Array(-1.9450381, dtype=float32), 'eval/episode_reward': Array(341.32812, dtype=float32), 'eval/episode_success': Array(341.32812, dtype=float32), 'eval/episode_success_easy': Array(664.22656, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.38305902481079, 'eval/sps': 3952.6840222824776}
Time elapsed: 0.380 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 11 out of 100 complete. metrics: {'eval/walltime': 385.2305688858032, 'training/sps': 11267.5968663132, 'training/walltime': 1101.1081652641296, 'training/envsteps': 12348416.0, 'training/actor_loss': Array(3.4304001, dtype=float32), 'training/alph_aloss': Array(0.00103715, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9360554, dtype=float32), 'training/log_alpha': Array(-2.5816772, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.14552963, dtype=float32), 'training/sample_entropy': Array(-1.9866376, dtype=float32), 'eval/episode_reward': Array(328.8203, dtype=float32), 'eval/episode_success': Array(328.8203, dtype=float32), 'eval/episode_success_easy': Array(687.4844, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.68237018585205, 'eval/sps': 3916.484614552534}
Time elapsed: 0.413 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 12 out of 100 complete. metrics: {'eval/walltime': 419.03376269340515, 'training/sps': 11254.547297036894, 'training/walltime': 1188.545178413391, 'training/envsteps': 13332480.0, 'training/actor_loss': Array(3.293349, dtype=float32), 'training/alph_aloss': Array(-0.00304022, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7836018, dtype=float32), 'training/log_alpha': Array(-2.5060236, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.15654604, dtype=float32), 'training/sample_entropy': Array(-2.0372095, dtype=float32), 'eval/episode_reward': Array(387.6172, dtype=float32), 'eval/episode_success': Array(387.6172, dtype=float32), 'eval/episode_success_easy': Array(734.52344, dtype=float32), 'eval/episode_success_any': Array(0.4375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.80319380760193, 'eval/sps': 3786.6244452680785}
Time elapsed: 0.447 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 13 out of 100 complete. metrics: {'eval/walltime': 448.4096703529358, 'training/sps': 11182.646616786864, 'training/walltime': 1276.5443823337555, 'training/envsteps': 14316544.0, 'training/actor_loss': Array(3.1700761, dtype=float32), 'training/alph_aloss': Array(-0.0028213, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6431565, dtype=float32), 'training/log_alpha': Array(-2.340221, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.16051587, dtype=float32), 'training/sample_entropy': Array(-2.0295231, dtype=float32), 'eval/episode_reward': Array(335.85156, dtype=float32), 'eval/episode_success': Array(335.85156, dtype=float32), 'eval/episode_success_easy': Array(679.71094, dtype=float32), 'eval/episode_success_any': Array(0.3828125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.37590765953064, 'eval/sps': 4357.31217171334}
Time elapsed: 0.479 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 14 out of 100 complete. metrics: {'eval/walltime': 470.668949842453, 'training/sps': 11204.715931478882, 'training/walltime': 1364.3702590465546, 'training/envsteps': 15300608.0, 'training/actor_loss': Array(3.140501, dtype=float32), 'training/alph_aloss': Array(-0.00128143, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6128483, dtype=float32), 'training/log_alpha': Array(-2.2360773, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.15376936, dtype=float32), 'training/sample_entropy': Array(-2.0122335, dtype=float32), 'eval/episode_reward': Array(409.03125, dtype=float32), 'eval/episode_success': Array(409.03125, dtype=float32), 'eval/episode_success_easy': Array(835.53906, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 22.259279489517212, 'eval/sps': 5750.410747134934}
Time elapsed: 0.510 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 15 out of 100 complete. metrics: {'eval/walltime': 495.09412026405334, 'training/sps': 11055.882533724316, 'training/walltime': 1453.378440618515, 'training/envsteps': 16284672.0, 'training/actor_loss': Array(3.165702, dtype=float32), 'training/alph_aloss': Array(-0.00016223, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6290545, dtype=float32), 'training/log_alpha': Array(-2.2270248, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.14005251, dtype=float32), 'training/sample_entropy': Array(-2.001595, dtype=float32), 'eval/episode_reward': Array(396.9922, dtype=float32), 'eval/episode_success': Array(396.9922, dtype=float32), 'eval/episode_success_easy': Array(765.15625, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 24.425170421600342, 'eval/sps': 5240.4956768204775}
Time elapsed: 0.541 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 16 out of 100 complete. metrics: {'eval/walltime': 519.3126828670502, 'training/sps': 11155.409247998861, 'training/walltime': 1541.5925059318542, 'training/envsteps': 17268736.0, 'training/actor_loss': Array(3.1436143, dtype=float32), 'training/alph_aloss': Array(-7.831128e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6250918, dtype=float32), 'training/log_alpha': Array(-2.210085, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12969582, dtype=float32), 'training/sample_entropy': Array(-2.0001838, dtype=float32), 'eval/episode_reward': Array(290.46094, dtype=float32), 'eval/episode_success': Array(290.46094, dtype=float32), 'eval/episode_success_easy': Array(671.5547, dtype=float32), 'eval/episode_success_any': Array(0.3671875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 24.218562602996826, 'eval/sps': 5285.20218554016}
Time elapsed: 0.573 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 17 out of 100 complete. metrics: {'eval/walltime': 541.040399312973, 'training/sps': 11154.347464970899, 'training/walltime': 1629.8149683475494, 'training/envsteps': 18252800.0, 'training/actor_loss': Array(3.1324937, dtype=float32), 'training/alph_aloss': Array(0.00048581, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6531148, dtype=float32), 'training/log_alpha': Array(-2.2287474, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12212708, dtype=float32), 'training/sample_entropy': Array(-1.9956204, dtype=float32), 'eval/episode_reward': Array(238.64062, dtype=float32), 'eval/episode_success': Array(238.64062, dtype=float32), 'eval/episode_success_easy': Array(632.6719, dtype=float32), 'eval/episode_success_any': Array(0.296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 21.72771644592285, 'eval/sps': 5891.093080056227}
Time elapsed: 0.603 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 18 out of 100 complete. metrics: {'eval/walltime': 562.8134503364563, 'training/sps': 11086.815301739844, 'training/walltime': 1718.5748126506805, 'training/envsteps': 19236864.0, 'training/actor_loss': Array(3.1403558, dtype=float32), 'training/alph_aloss': Array(0.00078509, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6869242, dtype=float32), 'training/log_alpha': Array(-2.2528827, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11683204, dtype=float32), 'training/sample_entropy': Array(-1.992704, dtype=float32), 'eval/episode_reward': Array(370.3203, dtype=float32), 'eval/episode_success': Array(370.3203, dtype=float32), 'eval/episode_success_easy': Array(749.8594, dtype=float32), 'eval/episode_success_any': Array(0.4375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 21.773051023483276, 'eval/sps': 5878.826989471796}
Time elapsed: 0.634 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 19 out of 100 complete. metrics: {'eval/walltime': 592.6341867446899, 'training/sps': 11125.972871352806, 'training/walltime': 1807.0222690105438, 'training/envsteps': 20220928.0, 'training/actor_loss': Array(3.1225317, dtype=float32), 'training/alph_aloss': Array(0.0001522, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.69043, dtype=float32), 'training/log_alpha': Array(-2.2639918, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11447585, dtype=float32), 'training/sample_entropy': Array(-1.9986441, dtype=float32), 'eval/episode_reward': Array(350.8125, dtype=float32), 'eval/episode_success': Array(350.8125, dtype=float32), 'eval/episode_success_easy': Array(773.35156, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.820736408233643, 'eval/sps': 4292.315194626066}
Time elapsed: 0.667 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 20 out of 100 complete. metrics: {'eval/walltime': 623.2560136318207, 'training/sps': 11172.004597758283, 'training/walltime': 1895.1052975654602, 'training/envsteps': 21204992.0, 'training/actor_loss': Array(3.117197, dtype=float32), 'training/alph_aloss': Array(-0.00074151, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6980162, dtype=float32), 'training/log_alpha': Array(-2.248245, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11108848, dtype=float32), 'training/sample_entropy': Array(-2.007149, dtype=float32), 'eval/episode_reward': Array(290.72656, dtype=float32), 'eval/episode_success': Array(290.72656, dtype=float32), 'eval/episode_success_easy': Array(734.3594, dtype=float32), 'eval/episode_success_any': Array(0.359375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.621826887130737, 'eval/sps': 4180.024936846398}
Time elapsed: 0.700 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 21 out of 100 complete. metrics: {'eval/walltime': 654.901736497879, 'training/sps': 11092.515249013282, 'training/walltime': 1983.8195321559906, 'training/envsteps': 22189056.0, 'training/actor_loss': Array(3.1219923, dtype=float32), 'training/alph_aloss': Array(-0.0003677, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7163074, dtype=float32), 'training/log_alpha': Array(-2.2365158, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10826588, dtype=float32), 'training/sample_entropy': Array(-2.0035198, dtype=float32), 'eval/episode_reward': Array(375.60156, dtype=float32), 'eval/episode_success': Array(375.60156, dtype=float32), 'eval/episode_success_easy': Array(726.5625, dtype=float32), 'eval/episode_success_any': Array(0.4453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.64572286605835, 'eval/sps': 4044.780412878055}
Time elapsed: 0.733 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 22 out of 100 complete. metrics: {'eval/walltime': 684.3576302528381, 'training/sps': 11207.39209302345, 'training/walltime': 2071.6244373321533, 'training/envsteps': 23173120.0, 'training/actor_loss': Array(3.1160774, dtype=float32), 'training/alph_aloss': Array(-5.557214e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.722327, dtype=float32), 'training/log_alpha': Array(-2.2257311, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10524019, dtype=float32), 'training/sample_entropy': Array(-2.0006294, dtype=float32), 'eval/episode_reward': Array(311.57812, dtype=float32), 'eval/episode_success': Array(311.57812, dtype=float32), 'eval/episode_success_easy': Array(718.7344, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.455893754959106, 'eval/sps': 4345.480095250897}
Time elapsed: 0.766 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 23 out of 100 complete. metrics: {'eval/walltime': 709.4724905490875, 'training/sps': 11212.994960244712, 'training/walltime': 2159.385468482971, 'training/envsteps': 24157184.0, 'training/actor_loss': Array(3.1184595, dtype=float32), 'training/alph_aloss': Array(-0.0002122, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7379496, dtype=float32), 'training/log_alpha': Array(-2.2096457, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10211077, dtype=float32), 'training/sample_entropy': Array(-2.002027, dtype=float32), 'eval/episode_reward': Array(285.64844, dtype=float32), 'eval/episode_success': Array(285.64844, dtype=float32), 'eval/episode_success_easy': Array(726.5, dtype=float32), 'eval/episode_success_any': Array(0.3515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 25.11486029624939, 'eval/sps': 5096.584193188417}
Time elapsed: 0.797 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 24 out of 100 complete. metrics: {'eval/walltime': 741.4242424964905, 'training/sps': 11220.439417261425, 'training/walltime': 2247.0882725715637, 'training/envsteps': 25141248.0, 'training/actor_loss': Array(3.1280324, dtype=float32), 'training/alph_aloss': Array(1.690882e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.75458, dtype=float32), 'training/log_alpha': Array(-2.2091448, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1005286, dtype=float32), 'training/sample_entropy': Array(-1.9999585, dtype=float32), 'eval/episode_reward': Array(394.52344, dtype=float32), 'eval/episode_success': Array(394.52344, dtype=float32), 'eval/episode_success_easy': Array(750.2656, dtype=float32), 'eval/episode_success_any': Array(0.5078125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.951751947402954, 'eval/sps': 4006.0401135657876}
Time elapsed: 0.830 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 25 out of 100 complete. metrics: {'eval/walltime': 771.4553062915802, 'training/sps': 11245.025507460196, 'training/walltime': 2334.5993235111237, 'training/envsteps': 26125312.0, 'training/actor_loss': Array(3.116107, dtype=float32), 'training/alph_aloss': Array(0.00025424, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7546442, dtype=float32), 'training/log_alpha': Array(-2.2218065, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09911934, dtype=float32), 'training/sample_entropy': Array(-1.9977931, dtype=float32), 'eval/episode_reward': Array(318.78125, dtype=float32), 'eval/episode_success': Array(318.78125, dtype=float32), 'eval/episode_success_easy': Array(726.09375, dtype=float32), 'eval/episode_success_any': Array(0.375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.03106379508972, 'eval/sps': 4262.253274588589}
Time elapsed: 0.863 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 26 out of 100 complete. metrics: {'eval/walltime': 804.2153205871582, 'training/sps': 11171.509594110803, 'training/walltime': 2422.68625497818, 'training/envsteps': 27109376.0, 'training/actor_loss': Array(3.1182399, dtype=float32), 'training/alph_aloss': Array(0.00011606, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.760577, dtype=float32), 'training/log_alpha': Array(-2.2074022, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09922793, dtype=float32), 'training/sample_entropy': Array(-1.9990442, dtype=float32), 'eval/episode_reward': Array(325.78906, dtype=float32), 'eval/episode_success': Array(325.78906, dtype=float32), 'eval/episode_success_easy': Array(749.7422, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.760014295578, 'eval/sps': 3907.2022022065366}
Time elapsed: 0.896 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 27 out of 100 complete. metrics: {'eval/walltime': 835.4109880924225, 'training/sps': 11210.062347932228, 'training/walltime': 2510.470244884491, 'training/envsteps': 28093440.0, 'training/actor_loss': Array(3.1235936, dtype=float32), 'training/alph_aloss': Array(-0.00044868, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7824857, dtype=float32), 'training/log_alpha': Array(-2.2021806, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0973002, dtype=float32), 'training/sample_entropy': Array(-2.0041797, dtype=float32), 'eval/episode_reward': Array(323.125, dtype=float32), 'eval/episode_success': Array(323.125, dtype=float32), 'eval/episode_success_easy': Array(748.3828, dtype=float32), 'eval/episode_success_any': Array(0.4140625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.195667505264282, 'eval/sps': 4103.133871983984}
Time elapsed: 0.929 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 28 out of 100 complete. metrics: {'eval/walltime': 855.5659501552582, 'training/sps': 11248.407740667939, 'training/walltime': 2597.95498251915, 'training/envsteps': 29077504.0, 'training/actor_loss': Array(3.1215944, dtype=float32), 'training/alph_aloss': Array(0.00065728, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.790106, dtype=float32), 'training/log_alpha': Array(-2.2042046, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09543768, dtype=float32), 'training/sample_entropy': Array(-1.994108, dtype=float32), 'eval/episode_reward': Array(354.08594, dtype=float32), 'eval/episode_success': Array(354.08594, dtype=float32), 'eval/episode_success_easy': Array(718.46875, dtype=float32), 'eval/episode_success_any': Array(0.4453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 20.154962062835693, 'eval/sps': 6350.793397722283}
Time elapsed: 0.959 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 29 out of 100 complete. metrics: {'eval/walltime': 891.05197930336, 'training/sps': 11212.855506432144, 'training/walltime': 2685.717105150223, 'training/envsteps': 30061568.0, 'training/actor_loss': Array(3.1230445, dtype=float32), 'training/alph_aloss': Array(0.00026387, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.799604, dtype=float32), 'training/log_alpha': Array(-2.227066, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09459548, dtype=float32), 'training/sample_entropy': Array(-1.9976563, dtype=float32), 'eval/episode_reward': Array(361.53906, dtype=float32), 'eval/episode_success': Array(361.53906, dtype=float32), 'eval/episode_success_easy': Array(698.28906, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 35.48602914810181, 'eval/sps': 3607.053341070901}
Time elapsed: 0.994 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 30 out of 100 complete. metrics: {'eval/walltime': 914.7127623558044, 'training/sps': 11283.713690396817, 'training/walltime': 2772.9281091690063, 'training/envsteps': 31045632.0, 'training/actor_loss': Array(3.1297228, dtype=float32), 'training/alph_aloss': Array(0.00034523, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8079982, dtype=float32), 'training/log_alpha': Array(-2.2295868, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09428889, dtype=float32), 'training/sample_entropy': Array(-1.9968582, dtype=float32), 'eval/episode_reward': Array(315.48438, dtype=float32), 'eval/episode_success': Array(315.48438, dtype=float32), 'eval/episode_success_easy': Array(741.83594, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 23.660783052444458, 'eval/sps': 5409.795597900805}
Time elapsed: 1.024 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 31 out of 100 complete. metrics: {'eval/walltime': 942.5086929798126, 'training/sps': 11243.331937629677, 'training/walltime': 2860.4523417949677, 'training/envsteps': 32029696.0, 'training/actor_loss': Array(3.1381, dtype=float32), 'training/alph_aloss': Array(-0.0003026, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8276863, dtype=float32), 'training/log_alpha': Array(-2.2454505, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09221641, dtype=float32), 'training/sample_entropy': Array(-2.0029345, dtype=float32), 'eval/episode_reward': Array(304.0703, dtype=float32), 'eval/episode_success': Array(304.0703, dtype=float32), 'eval/episode_success_easy': Array(703.22656, dtype=float32), 'eval/episode_success_any': Array(0.3828125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.79593062400818, 'eval/sps': 4604.990627277021}
Time elapsed: 1.056 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 32 out of 100 complete. metrics: {'eval/walltime': 969.7818684577942, 'training/sps': 11153.517865326197, 'training/walltime': 2948.6813662052155, 'training/envsteps': 33013760.0, 'training/actor_loss': Array(3.1305962, dtype=float32), 'training/alph_aloss': Array(0.00084759, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8178322, dtype=float32), 'training/log_alpha': Array(-2.2499604, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09236953, dtype=float32), 'training/sample_entropy': Array(-1.9920543, dtype=float32), 'eval/episode_reward': Array(305.85156, dtype=float32), 'eval/episode_success': Array(305.85156, dtype=float32), 'eval/episode_success_easy': Array(781.2031, dtype=float32), 'eval/episode_success_any': Array(0.4375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.273175477981567, 'eval/sps': 4693.2562034566945}
Time elapsed: 1.089 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 33 out of 100 complete. metrics: {'eval/walltime': 997.5489084720612, 'training/sps': 11167.894857661644, 'training/walltime': 3036.7968089580536, 'training/envsteps': 33997824.0, 'training/actor_loss': Array(3.1216776, dtype=float32), 'training/alph_aloss': Array(-0.00052406, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8105836, dtype=float32), 'training/log_alpha': Array(-2.2486916, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09143867, dtype=float32), 'training/sample_entropy': Array(-2.0051138, dtype=float32), 'eval/episode_reward': Array(302.625, dtype=float32), 'eval/episode_success': Array(302.625, dtype=float32), 'eval/episode_success_easy': Array(666.0547, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.767040014266968, 'eval/sps': 4609.7819549448695}
Time elapsed: 1.121 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 34 out of 100 complete. metrics: {'eval/walltime': 1029.9199421405792, 'training/sps': 11161.780420521294, 'training/walltime': 3124.9605214595795, 'training/envsteps': 34981888.0, 'training/actor_loss': Array(3.1245635, dtype=float32), 'training/alph_aloss': Array(0.00030767, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.81513, dtype=float32), 'training/log_alpha': Array(-2.2558033, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09004749, dtype=float32), 'training/sample_entropy': Array(-1.9971702, dtype=float32), 'eval/episode_reward': Array(265.34375, dtype=float32), 'eval/episode_success': Array(265.34375, dtype=float32), 'eval/episode_success_easy': Array(711.34375, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.371033668518066, 'eval/sps': 3954.1523854545417}
Time elapsed: 1.154 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 35 out of 100 complete. metrics: {'eval/walltime': 1060.4119944572449, 'training/sps': 11240.778303968556, 'training/walltime': 3212.504637479782, 'training/envsteps': 35965952.0, 'training/actor_loss': Array(3.1320279, dtype=float32), 'training/alph_aloss': Array(0.00064529, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8167202, dtype=float32), 'training/log_alpha': Array(-2.2697544, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.0899899, dtype=float32), 'training/sample_entropy': Array(-1.993815, dtype=float32), 'eval/episode_reward': Array(326.8672, dtype=float32), 'eval/episode_success': Array(326.8672, dtype=float32), 'eval/episode_success_easy': Array(729.97656, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.49205231666565, 'eval/sps': 4197.815177236879}
Time elapsed: 1.187 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 36 out of 100 complete. metrics: {'eval/walltime': 1091.9338648319244, 'training/sps': 11315.844654494207, 'training/walltime': 3299.4680087566376, 'training/envsteps': 36950016.0, 'training/actor_loss': Array(3.12518, dtype=float32), 'training/alph_aloss': Array(0.00015214, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8097494, dtype=float32), 'training/log_alpha': Array(-2.297116, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09075742, dtype=float32), 'training/sample_entropy': Array(-1.9985859, dtype=float32), 'eval/episode_reward': Array(295.83594, dtype=float32), 'eval/episode_success': Array(295.83594, dtype=float32), 'eval/episode_success_easy': Array(666.90625, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.521870374679565, 'eval/sps': 4060.6727481126245}
Time elapsed: 1.220 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 37 out of 100 complete. metrics: {'eval/walltime': 1125.2243053913116, 'training/sps': 11208.287068807282, 'training/walltime': 3387.2659027576447, 'training/envsteps': 37934080.0, 'training/actor_loss': Array(3.1262028, dtype=float32), 'training/alph_aloss': Array(0.00066027, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.818691, dtype=float32), 'training/log_alpha': Array(-2.3086267, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09152634, dtype=float32), 'training/sample_entropy': Array(-1.9934264, dtype=float32), 'eval/episode_reward': Array(323.4375, dtype=float32), 'eval/episode_success': Array(323.4375, dtype=float32), 'eval/episode_success_easy': Array(667.33594, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.29044055938721, 'eval/sps': 3844.947614065344}
Time elapsed: 1.254 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 38 out of 100 complete. metrics: {'eval/walltime': 1145.881863117218, 'training/sps': 11178.847911649276, 'training/walltime': 3475.2950098514557, 'training/envsteps': 38918144.0, 'training/actor_loss': Array(3.1408553, dtype=float32), 'training/alph_aloss': Array(9.611657e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.839779, dtype=float32), 'training/log_alpha': Array(-2.3366995, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09113311, dtype=float32), 'training/sample_entropy': Array(-1.9991124, dtype=float32), 'eval/episode_reward': Array(260.6875, dtype=float32), 'eval/episode_success': Array(260.6875, dtype=float32), 'eval/episode_success_easy': Array(676.7031, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 20.657557725906372, 'eval/sps': 6196.279429464059}
Time elapsed: 1.284 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 39 out of 100 complete. metrics: {'eval/walltime': 1178.551082611084, 'training/sps': 11231.802140111637, 'training/walltime': 3562.9090888500214, 'training/envsteps': 39902208.0, 'training/actor_loss': Array(3.1626544, dtype=float32), 'training/alph_aloss': Array(0.0009549, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8654695, dtype=float32), 'training/log_alpha': Array(-2.362872, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09213909, dtype=float32), 'training/sample_entropy': Array(-1.989972, dtype=float32), 'eval/episode_reward': Array(324., dtype=float32), 'eval/episode_success': Array(324., dtype=float32), 'eval/episode_success_easy': Array(687.5469, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.66921949386597, 'eval/sps': 3918.061159190948}
Time elapsed: 1.317 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 40 out of 100 complete. metrics: {'eval/walltime': 1210.7108898162842, 'training/sps': 11232.252860596353, 'training/walltime': 3650.5196521282196, 'training/envsteps': 40886272.0, 'training/actor_loss': Array(3.177231, dtype=float32), 'training/alph_aloss': Array(1.3182115e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8786077, dtype=float32), 'training/log_alpha': Array(-2.3730128, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09366476, dtype=float32), 'training/sample_entropy': Array(-1.9999567, dtype=float32), 'eval/episode_reward': Array(349.78906, dtype=float32), 'eval/episode_success': Array(349.78906, dtype=float32), 'eval/episode_success_easy': Array(731.46875, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.159807205200195, 'eval/sps': 3980.1233627825536}
Time elapsed: 1.350 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 41 out of 100 complete. metrics: {'eval/walltime': 1231.6176555156708, 'training/sps': 11231.185537527394, 'training/walltime': 3738.1385412216187, 'training/envsteps': 41870336.0, 'training/actor_loss': Array(3.1905117, dtype=float32), 'training/alph_aloss': Array(-3.1734955e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9003284, dtype=float32), 'training/log_alpha': Array(-2.3723488, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09506144, dtype=float32), 'training/sample_entropy': Array(-2.0004525, dtype=float32), 'eval/episode_reward': Array(315.70312, dtype=float32), 'eval/episode_success': Array(315.70312, dtype=float32), 'eval/episode_success_easy': Array(711.6719, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 20.906765699386597, 'eval/sps': 6122.419978320966}
Time elapsed: 1.381 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 42 out of 100 complete. metrics: {'eval/walltime': 1258.6448967456818, 'training/sps': 11264.992046220417, 'training/walltime': 3825.494483947754, 'training/envsteps': 42854400.0, 'training/actor_loss': Array(3.192767, dtype=float32), 'training/alph_aloss': Array(-0.00037476, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9065347, dtype=float32), 'training/log_alpha': Array(-2.371813, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09710578, dtype=float32), 'training/sample_entropy': Array(-2.0041215, dtype=float32), 'eval/episode_reward': Array(328.54688, dtype=float32), 'eval/episode_success': Array(328.54688, dtype=float32), 'eval/episode_success_easy': Array(750.0078, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.027241230010986, 'eval/sps': 4735.962465080198}
Time elapsed: 1.412 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 43 out of 100 complete. metrics: {'eval/walltime': 1287.2104613780975, 'training/sps': 11281.210842509388, 'training/walltime': 3912.724836587906, 'training/envsteps': 43838464.0, 'training/actor_loss': Array(3.1922154, dtype=float32), 'training/alph_aloss': Array(-6.169006e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9067838, dtype=float32), 'training/log_alpha': Array(-2.3623638, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.09939802, dtype=float32), 'training/sample_entropy': Array(-2.0007417, dtype=float32), 'eval/episode_reward': Array(308.64062, dtype=float32), 'eval/episode_success': Array(308.64062, dtype=float32), 'eval/episode_success_easy': Array(727.3203, dtype=float32), 'eval/episode_success_any': Array(0.4375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.56556463241577, 'eval/sps': 4480.91965438511}
Time elapsed: 1.445 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 44 out of 100 complete. metrics: {'eval/walltime': 1320.6917090415955, 'training/sps': 11290.195739600813, 'training/walltime': 3999.8857700824738, 'training/envsteps': 44822528.0, 'training/actor_loss': Array(3.2051651, dtype=float32), 'training/alph_aloss': Array(0.00027487, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9215987, dtype=float32), 'training/log_alpha': Array(-2.368869, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10157975, dtype=float32), 'training/sample_entropy': Array(-1.9971876, dtype=float32), 'eval/episode_reward': Array(261.03906, dtype=float32), 'eval/episode_success': Array(261.03906, dtype=float32), 'eval/episode_success_easy': Array(789.1875, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.481247663497925, 'eval/sps': 3823.0355477328503}
Time elapsed: 1.478 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 45 out of 100 complete. metrics: {'eval/walltime': 1344.0310688018799, 'training/sps': 11191.77929496049, 'training/walltime': 4087.8131651878357, 'training/envsteps': 45806592.0, 'training/actor_loss': Array(3.2278671, dtype=float32), 'training/alph_aloss': Array(0.00050618, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9418626, dtype=float32), 'training/log_alpha': Array(-2.3777246, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10119714, dtype=float32), 'training/sample_entropy': Array(-1.994593, dtype=float32), 'eval/episode_reward': Array(234.24219, dtype=float32), 'eval/episode_success': Array(234.24219, dtype=float32), 'eval/episode_success_easy': Array(676.75, dtype=float32), 'eval/episode_success_any': Array(0.3515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 23.339359760284424, 'eval/sps': 5484.29782627594}
Time elapsed: 1.509 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 46 out of 100 complete. metrics: {'eval/walltime': 1376.9889357089996, 'training/sps': 11148.580559260197, 'training/walltime': 4176.081263065338, 'training/envsteps': 46790656.0, 'training/actor_loss': Array(3.2622952, dtype=float32), 'training/alph_aloss': Array(0.00026244, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9752522, dtype=float32), 'training/log_alpha': Array(-2.4051738, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10156503, dtype=float32), 'training/sample_entropy': Array(-1.9971832, dtype=float32), 'eval/episode_reward': Array(260.82812, dtype=float32), 'eval/episode_success': Array(260.82812, dtype=float32), 'eval/episode_success_easy': Array(767.83594, dtype=float32), 'eval/episode_success_any': Array(0.421875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.95786690711975, 'eval/sps': 3883.746492475479}
Time elapsed: 1.543 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 47 out of 100 complete. metrics: {'eval/walltime': 1399.3387832641602, 'training/sps': 11194.27066626042, 'training/walltime': 4263.989089250565, 'training/envsteps': 47774720.0, 'training/actor_loss': Array(3.2990718, dtype=float32), 'training/alph_aloss': Array(0.00020877, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.0172405, dtype=float32), 'training/log_alpha': Array(-2.4352477, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1009187, dtype=float32), 'training/sample_entropy': Array(-1.9977573, dtype=float32), 'eval/episode_reward': Array(341.60156, dtype=float32), 'eval/episode_success': Array(341.60156, dtype=float32), 'eval/episode_success_easy': Array(712.3281, dtype=float32), 'eval/episode_success_any': Array(0.4453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 22.349847555160522, 'eval/sps': 5727.108414681116}
Time elapsed: 1.573 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 48 out of 100 complete. metrics: {'eval/walltime': 1429.7058053016663, 'training/sps': 11162.348279850046, 'training/walltime': 4352.14831662178, 'training/envsteps': 48758784.0, 'training/actor_loss': Array(3.3312736, dtype=float32), 'training/alph_aloss': Array(0.00086586, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.0495715, dtype=float32), 'training/log_alpha': Array(-2.461742, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10122006, dtype=float32), 'training/sample_entropy': Array(-1.9899331, dtype=float32), 'eval/episode_reward': Array(259.6172, dtype=float32), 'eval/episode_success': Array(259.6172, dtype=float32), 'eval/episode_success_easy': Array(762.4922, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.367022037506104, 'eval/sps': 4215.098860925779}
Time elapsed: 1.606 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 49 out of 100 complete. metrics: {'eval/walltime': 1456.4076952934265, 'training/sps': 11159.270903867284, 'training/walltime': 4440.331855535507, 'training/envsteps': 49742848.0, 'training/actor_loss': Array(3.3424535, dtype=float32), 'training/alph_aloss': Array(0.00024079, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.0666366, dtype=float32), 'training/log_alpha': Array(-2.4846554, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10169072, dtype=float32), 'training/sample_entropy': Array(-1.9971658, dtype=float32), 'eval/episode_reward': Array(225.32812, dtype=float32), 'eval/episode_success': Array(225.32812, dtype=float32), 'eval/episode_success_easy': Array(647.875, dtype=float32), 'eval/episode_success_any': Array(0.3359375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 26.701889991760254, 'eval/sps': 4793.668165043696}
Time elapsed: 1.638 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 50 out of 100 complete. metrics: {'eval/walltime': 1489.831042289734, 'training/sps': 11166.027060141654, 'training/walltime': 4528.462037801743, 'training/envsteps': 50726912.0, 'training/actor_loss': Array(3.3674302, dtype=float32), 'training/alph_aloss': Array(-0.00014255, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.091761, dtype=float32), 'training/log_alpha': Array(-2.5159245, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10202302, dtype=float32), 'training/sample_entropy': Array(-2.0018492, dtype=float32), 'eval/episode_reward': Array(348.75, dtype=float32), 'eval/episode_success': Array(348.75, dtype=float32), 'eval/episode_success_easy': Array(706.625, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.42334699630737, 'eval/sps': 3829.658352711998}
Time elapsed: 1.672 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 51 out of 100 complete. metrics: {'eval/walltime': 1514.0682256221771, 'training/sps': 11170.241139626989, 'training/walltime': 4616.558972120285, 'training/envsteps': 51710976.0, 'training/actor_loss': Array(3.3792708, dtype=float32), 'training/alph_aloss': Array(0.00038752, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.102403, dtype=float32), 'training/log_alpha': Array(-2.5236533, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10191886, dtype=float32), 'training/sample_entropy': Array(-1.9953009, dtype=float32), 'eval/episode_reward': Array(240.66406, dtype=float32), 'eval/episode_success': Array(240.66406, dtype=float32), 'eval/episode_success_easy': Array(675.16406, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 24.237183332443237, 'eval/sps': 5281.141717018852}
Time elapsed: 1.703 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 52 out of 100 complete. metrics: {'eval/walltime': 1546.9833714962006, 'training/sps': 11208.52603115636, 'training/walltime': 4704.354994297028, 'training/envsteps': 52695040.0, 'training/actor_loss': Array(3.3836722, dtype=float32), 'training/alph_aloss': Array(0.00010106, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.1071854, dtype=float32), 'training/log_alpha': Array(-2.5286777, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10323955, dtype=float32), 'training/sample_entropy': Array(-1.998831, dtype=float32), 'eval/episode_reward': Array(383.6172, dtype=float32), 'eval/episode_success': Array(383.6172, dtype=float32), 'eval/episode_success_easy': Array(747.375, dtype=float32), 'eval/episode_success_any': Array(0.53125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.91514587402344, 'eval/sps': 3888.7872619460977}
Time elapsed: 1.737 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 53 out of 100 complete. metrics: {'eval/walltime': 1577.7501935958862, 'training/sps': 11194.619215202016, 'training/walltime': 4792.260083436966, 'training/envsteps': 53679104.0, 'training/actor_loss': Array(3.3803723, dtype=float32), 'training/alph_aloss': Array(7.815417e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.104583, dtype=float32), 'training/log_alpha': Array(-2.5359268, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10452549, dtype=float32), 'training/sample_entropy': Array(-1.999115, dtype=float32), 'eval/episode_reward': Array(318.1172, dtype=float32), 'eval/episode_success': Array(318.1172, dtype=float32), 'eval/episode_success_easy': Array(713.78125, dtype=float32), 'eval/episode_success_any': Array(0.484375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.76682209968567, 'eval/sps': 4160.325677617115}
Time elapsed: 1.770 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 54 out of 100 complete. metrics: {'eval/walltime': 1610.571367263794, 'training/sps': 11164.848187740201, 'training/walltime': 4880.399571180344, 'training/envsteps': 54663168.0, 'training/actor_loss': Array(3.3688447, dtype=float32), 'training/alph_aloss': Array(-6.560399e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.092612, dtype=float32), 'training/log_alpha': Array(-2.521328, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10868447, dtype=float32), 'training/sample_entropy': Array(-2.000939, dtype=float32), 'eval/episode_reward': Array(282.8672, dtype=float32), 'eval/episode_success': Array(282.8672, dtype=float32), 'eval/episode_success_easy': Array(729.0703, dtype=float32), 'eval/episode_success_any': Array(0.46875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.821173667907715, 'eval/sps': 3899.9214743242833}
Time elapsed: 1.803 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 55 out of 100 complete. metrics: {'eval/walltime': 1642.6592934131622, 'training/sps': 11169.298911751599, 'training/walltime': 4968.503937244415, 'training/envsteps': 55647232.0, 'training/actor_loss': Array(3.35789, dtype=float32), 'training/alph_aloss': Array(-0.00015853, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.080497, dtype=float32), 'training/log_alpha': Array(-2.5237305, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11018774, dtype=float32), 'training/sample_entropy': Array(-2.002091, dtype=float32), 'eval/episode_reward': Array(295.5547, dtype=float32), 'eval/episode_success': Array(295.5547, dtype=float32), 'eval/episode_success_easy': Array(675.0469, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.087926149368286, 'eval/sps': 3989.0393478270935}
Time elapsed: 1.837 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 56 out of 100 complete. metrics: {'eval/walltime': 1664.2187714576721, 'training/sps': 11173.291812561525, 'training/walltime': 5056.576818227768, 'training/envsteps': 56631296.0, 'training/actor_loss': Array(3.34593, dtype=float32), 'training/alph_aloss': Array(0.00010752, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.065372, dtype=float32), 'training/log_alpha': Array(-2.5262437, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11124481, dtype=float32), 'training/sample_entropy': Array(-1.9987606, dtype=float32), 'eval/episode_reward': Array(289.8203, dtype=float32), 'eval/episode_success': Array(289.8203, dtype=float32), 'eval/episode_success_easy': Array(624.1172, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 21.559478044509888, 'eval/sps': 5937.063955618125}
Time elapsed: 1.867 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 57 out of 100 complete. metrics: {'eval/walltime': 1696.4525678157806, 'training/sps': 11225.210644618937, 'training/walltime': 5144.242344617844, 'training/envsteps': 57615360.0, 'training/actor_loss': Array(3.321119, dtype=float32), 'training/alph_aloss': Array(7.163852e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.0409484, dtype=float32), 'training/log_alpha': Array(-2.5303018, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11321031, dtype=float32), 'training/sample_entropy': Array(-1.9992012, dtype=float32), 'eval/episode_reward': Array(221.32812, dtype=float32), 'eval/episode_success': Array(221.32812, dtype=float32), 'eval/episode_success_easy': Array(666.83594, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.23379635810852, 'eval/sps': 3970.987425060194}
Time elapsed: 1.900 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 58 out of 100 complete. metrics: {'eval/walltime': 1724.4498438835144, 'training/sps': 11197.279953787855, 'training/walltime': 5232.12654542923, 'training/envsteps': 58599424.0, 'training/actor_loss': Array(3.3084748, dtype=float32), 'training/alph_aloss': Array(7.276939e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(4.0212703, dtype=float32), 'training/log_alpha': Array(-2.543425, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11531209, dtype=float32), 'training/sample_entropy': Array(-1.9991649, dtype=float32), 'eval/episode_reward': Array(235.6875, dtype=float32), 'eval/episode_success': Array(235.6875, dtype=float32), 'eval/episode_success_easy': Array(615.7031, dtype=float32), 'eval/episode_success_any': Array(0.3515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.997276067733765, 'eval/sps': 4571.873338332265}
Time elapsed: 1.933 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 59 out of 100 complete. metrics: {'eval/walltime': 1754.1079785823822, 'training/sps': 11239.639269548854, 'training/walltime': 5319.679533243179, 'training/envsteps': 59583488.0, 'training/actor_loss': Array(3.2774475, dtype=float32), 'training/alph_aloss': Array(3.6250776e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.982593, dtype=float32), 'training/log_alpha': Array(-2.532939, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11692379, dtype=float32), 'training/sample_entropy': Array(-2.0000408, dtype=float32), 'eval/episode_reward': Array(227.57812, dtype=float32), 'eval/episode_success': Array(227.57812, dtype=float32), 'eval/episode_success_easy': Array(560.5703, dtype=float32), 'eval/episode_success_any': Array(0.3828125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.658134698867798, 'eval/sps': 4315.84795536337}
Time elapsed: 1.965 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 60 out of 100 complete. metrics: {'eval/walltime': 1785.8406319618225, 'training/sps': 11202.362351833337, 'training/walltime': 5407.523861885071, 'training/envsteps': 60567552.0, 'training/actor_loss': Array(3.2489064, dtype=float32), 'training/alph_aloss': Array(-3.1202253e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9461014, dtype=float32), 'training/log_alpha': Array(-2.538379, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11942904, dtype=float32), 'training/sample_entropy': Array(-2.0004854, dtype=float32), 'eval/episode_reward': Array(271.84375, dtype=float32), 'eval/episode_success': Array(271.84375, dtype=float32), 'eval/episode_success_easy': Array(633.0703, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.732653379440308, 'eval/sps': 4033.699875943297}
Time elapsed: 1.998 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 61 out of 100 complete. metrics: {'eval/walltime': 1814.7816598415375, 'training/sps': 11223.172900082787, 'training/walltime': 5495.205305337906, 'training/envsteps': 61551616.0, 'training/actor_loss': Array(3.217633, dtype=float32), 'training/alph_aloss': Array(0.00010174, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9050484, dtype=float32), 'training/log_alpha': Array(-2.5326838, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1222766, dtype=float32), 'training/sample_entropy': Array(-1.998797, dtype=float32), 'eval/episode_reward': Array(263.9375, dtype=float32), 'eval/episode_success': Array(263.9375, dtype=float32), 'eval/episode_success_easy': Array(631.46094, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.941027879714966, 'eval/sps': 4422.786935280775}
Time elapsed: 2.031 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 62 out of 100 complete. metrics: {'eval/walltime': 1843.1151509284973, 'training/sps': 11155.54709564491, 'training/walltime': 5583.4182806015015, 'training/envsteps': 62535680.0, 'training/actor_loss': Array(3.1828215, dtype=float32), 'training/alph_aloss': Array(-0.00019192, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8709502, dtype=float32), 'training/log_alpha': Array(-2.5331938, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12301306, dtype=float32), 'training/sample_entropy': Array(-2.0025153, dtype=float32), 'eval/episode_reward': Array(246.46094, dtype=float32), 'eval/episode_success': Array(246.46094, dtype=float32), 'eval/episode_success_easy': Array(638.3906, dtype=float32), 'eval/episode_success_any': Array(0.4140625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.33349108695984, 'eval/sps': 4517.621905720983}
Time elapsed: 2.063 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 63 out of 100 complete. metrics: {'eval/walltime': 1863.9678268432617, 'training/sps': 11201.165672534426, 'training/walltime': 5671.271994113922, 'training/envsteps': 63519744.0, 'training/actor_loss': Array(3.1493556, dtype=float32), 'training/alph_aloss': Array(-4.66925e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8314977, dtype=float32), 'training/log_alpha': Array(-2.5271623, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1244211, dtype=float32), 'training/sample_entropy': Array(-2.0006652, dtype=float32), 'eval/episode_reward': Array(261.57812, dtype=float32), 'eval/episode_success': Array(261.57812, dtype=float32), 'eval/episode_success_easy': Array(608.85156, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 20.852675914764404, 'eval/sps': 6138.300931890072}
Time elapsed: 2.093 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 64 out of 100 complete. metrics: {'eval/walltime': 1895.942138671875, 'training/sps': 11265.640224877101, 'training/walltime': 5758.622910737991, 'training/envsteps': 64503808.0, 'training/actor_loss': Array(3.1253252, dtype=float32), 'training/alph_aloss': Array(-9.149697e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8044848, dtype=float32), 'training/log_alpha': Array(-2.5215821, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12379976, dtype=float32), 'training/sample_entropy': Array(-2.001232, dtype=float32), 'eval/episode_reward': Array(263.28125, dtype=float32), 'eval/episode_success': Array(263.28125, dtype=float32), 'eval/episode_success_easy': Array(562.1328, dtype=float32), 'eval/episode_success_any': Array(0.34375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.97431182861328, 'eval/sps': 4003.213601158882}
Time elapsed: 2.126 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 65 out of 100 complete. metrics: {'eval/walltime': 1927.2997751235962, 'training/sps': 11306.471416922246, 'training/walltime': 5845.65837597847, 'training/envsteps': 65487872.0, 'training/actor_loss': Array(3.1104608, dtype=float32), 'training/alph_aloss': Array(0.00021643, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7871099, dtype=float32), 'training/log_alpha': Array(-2.517935, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1233209, dtype=float32), 'training/sample_entropy': Array(-1.997394, dtype=float32), 'eval/episode_reward': Array(227.86719, dtype=float32), 'eval/episode_success': Array(227.86719, dtype=float32), 'eval/episode_success_easy': Array(537.625, dtype=float32), 'eval/episode_success_any': Array(0.3046875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.35763645172119, 'eval/sps': 4081.9403017530103}
Time elapsed: 2.159 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 66 out of 100 complete. metrics: {'eval/walltime': 1962.157889842987, 'training/sps': 11355.190089997286, 'training/walltime': 5932.320421457291, 'training/envsteps': 66471936.0, 'training/actor_loss': Array(3.1075635, dtype=float32), 'training/alph_aloss': Array(3.4305742e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7833023, dtype=float32), 'training/log_alpha': Array(-2.5225203, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12274771, dtype=float32), 'training/sample_entropy': Array(-2.0000381, dtype=float32), 'eval/episode_reward': Array(267.1875, dtype=float32), 'eval/episode_success': Array(267.1875, dtype=float32), 'eval/episode_success_easy': Array(543.1094, dtype=float32), 'eval/episode_success_any': Array(0.3828125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.85811471939087, 'eval/sps': 3672.0287666273634}
Time elapsed: 2.193 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 67 out of 100 complete. metrics: {'eval/walltime': 1994.118525981903, 'training/sps': 11337.932389412945, 'training/walltime': 6019.11437702179, 'training/envsteps': 67456000.0, 'training/actor_loss': Array(3.1032593, dtype=float32), 'training/alph_aloss': Array(-0.00022737, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7747512, dtype=float32), 'training/log_alpha': Array(-2.5150042, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12312981, dtype=float32), 'training/sample_entropy': Array(-2.00291, dtype=float32), 'eval/episode_reward': Array(283.8203, dtype=float32), 'eval/episode_success': Array(283.8203, dtype=float32), 'eval/episode_success_easy': Array(564.7344, dtype=float32), 'eval/episode_success_any': Array(0.3984375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.960636138916016, 'eval/sps': 4004.926542877669}
Time elapsed: 2.226 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 68 out of 100 complete. metrics: {'eval/walltime': 2027.2837722301483, 'training/sps': 11343.749937010369, 'training/walltime': 6105.863821029663, 'training/envsteps': 68440064.0, 'training/actor_loss': Array(3.0984502, dtype=float32), 'training/alph_aloss': Array(0.00034315, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7684672, dtype=float32), 'training/log_alpha': Array(-2.524357, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12323932, dtype=float32), 'training/sample_entropy': Array(-1.9957945, dtype=float32), 'eval/episode_reward': Array(237.11719, dtype=float32), 'eval/episode_success': Array(237.11719, dtype=float32), 'eval/episode_success_easy': Array(578.21094, dtype=float32), 'eval/episode_success_any': Array(0.375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.16524624824524, 'eval/sps': 3859.4617703697113}
Time elapsed: 2.259 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 69 out of 100 complete. metrics: {'eval/walltime': 2058.741331577301, 'training/sps': 11243.225202968497, 'training/walltime': 6193.388884544373, 'training/envsteps': 69424128.0, 'training/actor_loss': Array(3.092541, dtype=float32), 'training/alph_aloss': Array(8.714087e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7570627, dtype=float32), 'training/log_alpha': Array(-2.537426, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12392229, dtype=float32), 'training/sample_entropy': Array(-1.9989709, dtype=float32), 'eval/episode_reward': Array(244.88281, dtype=float32), 'eval/episode_success': Array(244.88281, dtype=float32), 'eval/episode_success_easy': Array(609.47656, dtype=float32), 'eval/episode_success_any': Array(0.359375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.45755934715271, 'eval/sps': 4068.9742833334444}
Time elapsed: 2.292 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 70 out of 100 complete. metrics: {'eval/walltime': 2092.9962055683136, 'training/sps': 11337.863933724451, 'training/walltime': 6280.183364152908, 'training/envsteps': 70408192.0, 'training/actor_loss': Array(3.0882235, dtype=float32), 'training/alph_aloss': Array(4.33408e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.744145, dtype=float32), 'training/log_alpha': Array(-2.5444582, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12511876, dtype=float32), 'training/sample_entropy': Array(-1.999528, dtype=float32), 'eval/episode_reward': Array(279.47656, dtype=float32), 'eval/episode_success': Array(279.47656, dtype=float32), 'eval/episode_success_easy': Array(552.71875, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.25487399101257, 'eval/sps': 3736.6945221746623}
Time elapsed: 2.326 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 71 out of 100 complete. metrics: {'eval/walltime': 2127.0735828876495, 'training/sps': 11393.376352459536, 'training/walltime': 6366.554951429367, 'training/envsteps': 71392256.0, 'training/actor_loss': Array(3.0681756, dtype=float32), 'training/alph_aloss': Array(-0.00024202, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7202468, dtype=float32), 'training/log_alpha': Array(-2.5446267, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12646821, dtype=float32), 'training/sample_entropy': Array(-2.0031676, dtype=float32), 'eval/episode_reward': Array(211.32031, dtype=float32), 'eval/episode_success': Array(211.32031, dtype=float32), 'eval/episode_success_easy': Array(568.2344, dtype=float32), 'eval/episode_success_any': Array(0.3125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.07737731933594, 'eval/sps': 3756.157605690247}
Time elapsed: 2.359 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 72 out of 100 complete. metrics: {'eval/walltime': 2152.73934674263, 'training/sps': 11396.543342690418, 'training/walltime': 6452.902536869049, 'training/envsteps': 72376320.0, 'training/actor_loss': Array(3.0576696, dtype=float32), 'training/alph_aloss': Array(0.00011992, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7053099, dtype=float32), 'training/log_alpha': Array(-2.5474715, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12745051, dtype=float32), 'training/sample_entropy': Array(-1.9985532, dtype=float32), 'eval/episode_reward': Array(259.7578, dtype=float32), 'eval/episode_success': Array(259.7578, dtype=float32), 'eval/episode_success_easy': Array(558.9922, dtype=float32), 'eval/episode_success_any': Array(0.3828125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 25.66576385498047, 'eval/sps': 4987.188408778314}
Time elapsed: 2.391 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 73 out of 100 complete. metrics: {'eval/walltime': 2173.079750776291, 'training/sps': 11424.409502368231, 'training/walltime': 6539.039505243301, 'training/envsteps': 73360384.0, 'training/actor_loss': Array(3.041238, dtype=float32), 'training/alph_aloss': Array(-0.00012014, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6880028, dtype=float32), 'training/log_alpha': Array(-2.5339055, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12866123, dtype=float32), 'training/sample_entropy': Array(-2.0015986, dtype=float32), 'eval/episode_reward': Array(256.17188, dtype=float32), 'eval/episode_success': Array(256.17188, dtype=float32), 'eval/episode_success_easy': Array(604.46875, dtype=float32), 'eval/episode_success_any': Array(0.3359375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 20.34040403366089, 'eval/sps': 6292.89368038981}
Time elapsed: 2.420 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 74 out of 100 complete. metrics: {'eval/walltime': 2205.1804101467133, 'training/sps': 11321.549957968495, 'training/walltime': 6625.959052801132, 'training/envsteps': 74344448.0, 'training/actor_loss': Array(3.0225563, dtype=float32), 'training/alph_aloss': Array(-1.0469845e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6695793, dtype=float32), 'training/log_alpha': Array(-2.5226963, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12958069, dtype=float32), 'training/sample_entropy': Array(-2.000222, dtype=float32), 'eval/episode_reward': Array(331.21094, dtype=float32), 'eval/episode_success': Array(331.21094, dtype=float32), 'eval/episode_success_easy': Array(592.84375, dtype=float32), 'eval/episode_success_any': Array(0.4921875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.10065937042236, 'eval/sps': 3987.457033918112}
Time elapsed: 2.453 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 75 out of 100 complete. metrics: {'eval/walltime': 2230.6511158943176, 'training/sps': 11318.64990461331, 'training/walltime': 6712.900870800018, 'training/envsteps': 75328512.0, 'training/actor_loss': Array(3.0032134, dtype=float32), 'training/alph_aloss': Array(-0.00027868, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6580114, dtype=float32), 'training/log_alpha': Array(-2.503877, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.13012017, dtype=float32), 'training/sample_entropy': Array(-2.0035355, dtype=float32), 'eval/episode_reward': Array(332.10938, dtype=float32), 'eval/episode_success': Array(332.10938, dtype=float32), 'eval/episode_success_easy': Array(606.7031, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 25.47070574760437, 'eval/sps': 5025.380971708605}
Time elapsed: 2.484 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 76 out of 100 complete. metrics: {'eval/walltime': 2257.7048728466034, 'training/sps': 11391.62488421253, 'training/walltime': 6799.285737752914, 'training/envsteps': 76312576.0, 'training/actor_loss': Array(3.0011141, dtype=float32), 'training/alph_aloss': Array(-4.5079956e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6554966, dtype=float32), 'training/log_alpha': Array(-2.501205, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12937127, dtype=float32), 'training/sample_entropy': Array(-2.0006318, dtype=float32), 'eval/episode_reward': Array(336.59375, dtype=float32), 'eval/episode_success': Array(336.59375, dtype=float32), 'eval/episode_success_easy': Array(654.46094, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.053756952285767, 'eval/sps': 4731.3206896088905}
Time elapsed: 2.516 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 77 out of 100 complete. metrics: {'eval/walltime': 2288.8050606250763, 'training/sps': 11358.61348326186, 'training/walltime': 6885.9216639995575, 'training/envsteps': 77296640.0, 'training/actor_loss': Array(2.999859, dtype=float32), 'training/alph_aloss': Array(8.015121e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6586475, dtype=float32), 'training/log_alpha': Array(-2.504996, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12767524, dtype=float32), 'training/sample_entropy': Array(-1.9991074, dtype=float32), 'eval/episode_reward': Array(215.71875, dtype=float32), 'eval/episode_success': Array(215.71875, dtype=float32), 'eval/episode_success_easy': Array(639.53906, dtype=float32), 'eval/episode_success_any': Array(0.3515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 31.1001877784729, 'eval/sps': 4115.73077666752}
Time elapsed: 2.549 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 78 out of 100 complete. metrics: {'eval/walltime': 2322.921504497528, 'training/sps': 11363.366129759328, 'training/walltime': 6972.521355390549, 'training/envsteps': 78280704.0, 'training/actor_loss': Array(3.0079575, dtype=float32), 'training/alph_aloss': Array(-0.00012873, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6784537, dtype=float32), 'training/log_alpha': Array(-2.492263, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12408503, dtype=float32), 'training/sample_entropy': Array(-2.0016541, dtype=float32), 'eval/episode_reward': Array(305.5703, dtype=float32), 'eval/episode_success': Array(305.5703, dtype=float32), 'eval/episode_success_easy': Array(614.90625, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 34.11644387245178, 'eval/sps': 3751.856450178178}
Time elapsed: 2.582 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 79 out of 100 complete. metrics: {'eval/walltime': 2356.6201956272125, 'training/sps': 11379.475575750648, 'training/walltime': 7058.99845123291, 'training/envsteps': 79264768.0, 'training/actor_loss': Array(3.0206838, dtype=float32), 'training/alph_aloss': Array(-9.155957e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6919239, dtype=float32), 'training/log_alpha': Array(-2.4970505, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12251744, dtype=float32), 'training/sample_entropy': Array(-2.0011833, dtype=float32), 'eval/episode_reward': Array(296.77344, dtype=float32), 'eval/episode_success': Array(296.77344, dtype=float32), 'eval/episode_success_easy': Array(529.53906, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.69869112968445, 'eval/sps': 3798.3671089007835}
Time elapsed: 2.616 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 80 out of 100 complete. metrics: {'eval/walltime': 2379.6075007915497, 'training/sps': 11389.854184477987, 'training/walltime': 7145.39674782753, 'training/envsteps': 80248832.0, 'training/actor_loss': Array(3.019171, dtype=float32), 'training/alph_aloss': Array(1.8506782e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6990297, dtype=float32), 'training/log_alpha': Array(-2.4841375, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12185213, dtype=float32), 'training/sample_entropy': Array(-1.9998629, dtype=float32), 'eval/episode_reward': Array(194.45312, dtype=float32), 'eval/episode_success': Array(194.45312, dtype=float32), 'eval/episode_success_easy': Array(452.83594, dtype=float32), 'eval/episode_success_any': Array(0.2890625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 22.987305164337158, 'eval/sps': 5568.290805943669}
Time elapsed: 2.646 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 81 out of 100 complete. metrics: {'eval/walltime': 2409.1132736206055, 'training/sps': 11463.430420339, 'training/walltime': 7231.240510463715, 'training/envsteps': 81232896.0, 'training/actor_loss': Array(3.0151362, dtype=float32), 'training/alph_aloss': Array(-1.376652e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.696754, dtype=float32), 'training/log_alpha': Array(-2.483134, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12399193, dtype=float32), 'training/sample_entropy': Array(-2.000249, dtype=float32), 'eval/episode_reward': Array(273.0625, dtype=float32), 'eval/episode_success': Array(273.0625, dtype=float32), 'eval/episode_success_easy': Array(632.66406, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 29.505772829055786, 'eval/sps': 4338.134125195735}
Time elapsed: 2.678 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 82 out of 100 complete. metrics: {'eval/walltime': 2443.023512363434, 'training/sps': 11415.84036952479, 'training/walltime': 7317.442136287689, 'training/envsteps': 82216960.0, 'training/actor_loss': Array(3.0154512, dtype=float32), 'training/alph_aloss': Array(0.000188, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.6992, dtype=float32), 'training/log_alpha': Array(-2.4841802, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12231867, dtype=float32), 'training/sample_entropy': Array(-1.997828, dtype=float32), 'eval/episode_reward': Array(290.875, dtype=float32), 'eval/episode_success': Array(290.875, dtype=float32), 'eval/episode_success_easy': Array(676.2031, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.91023874282837, 'eval/sps': 3774.6711537697606}
Time elapsed: 2.711 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 83 out of 100 complete. metrics: {'eval/walltime': 2476.8237409591675, 'training/sps': 11354.436984251097, 'training/walltime': 7404.109929800034, 'training/envsteps': 83201024.0, 'training/actor_loss': Array(3.0255747, dtype=float32), 'training/alph_aloss': Array(-4.2248514e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7069855, dtype=float32), 'training/log_alpha': Array(-2.488735, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1219006, dtype=float32), 'training/sample_entropy': Array(-2.0005937, dtype=float32), 'eval/episode_reward': Array(266.35156, dtype=float32), 'eval/episode_success': Array(266.35156, dtype=float32), 'eval/episode_success_easy': Array(663.21094, dtype=float32), 'eval/episode_success_any': Array(0.3671875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.80022859573364, 'eval/sps': 3786.9566366233544}
Time elapsed: 2.745 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 84 out of 100 complete. metrics: {'eval/walltime': 2505.553031682968, 'training/sps': 11420.179525633457, 'training/walltime': 7490.278802871704, 'training/envsteps': 84185088.0, 'training/actor_loss': Array(3.0372539, dtype=float32), 'training/alph_aloss': Array(-0.00014215, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7198486, dtype=float32), 'training/log_alpha': Array(-2.4796126, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.12045676, dtype=float32), 'training/sample_entropy': Array(-2.001793, dtype=float32), 'eval/episode_reward': Array(273.4375, dtype=float32), 'eval/episode_success': Array(273.4375, dtype=float32), 'eval/episode_success_easy': Array(670., dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.72929072380066, 'eval/sps': 4455.38322649779}
Time elapsed: 2.777 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 85 out of 100 complete. metrics: {'eval/walltime': 2533.507994413376, 'training/sps': 11427.296021598358, 'training/walltime': 7576.394013166428, 'training/envsteps': 85169152.0, 'training/actor_loss': Array(3.0511875, dtype=float32), 'training/alph_aloss': Array(0.0001824, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7429457, dtype=float32), 'training/log_alpha': Array(-2.4766316, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11760109, dtype=float32), 'training/sample_entropy': Array(-1.9979112, dtype=float32), 'eval/episode_reward': Array(230.21875, dtype=float32), 'eval/episode_success': Array(230.21875, dtype=float32), 'eval/episode_success_easy': Array(504.7578, dtype=float32), 'eval/episode_success_any': Array(0.3515625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 27.954962730407715, 'eval/sps': 4578.793441236441}
Time elapsed: 2.808 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 86 out of 100 complete. metrics: {'eval/walltime': 2562.283574819565, 'training/sps': 11322.264822142672, 'training/walltime': 7663.308072805405, 'training/envsteps': 86153216.0, 'training/actor_loss': Array(3.0755742, dtype=float32), 'training/alph_aloss': Array(-5.520621e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7656095, dtype=float32), 'training/log_alpha': Array(-2.4872096, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11708686, dtype=float32), 'training/sample_entropy': Array(-2.0001657, dtype=float32), 'eval/episode_reward': Array(200.91406, dtype=float32), 'eval/episode_success': Array(200.91406, dtype=float32), 'eval/episode_success_easy': Array(617.8672, dtype=float32), 'eval/episode_success_any': Array(0.375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 28.775580406188965, 'eval/sps': 4448.21609827443}
Time elapsed: 2.841 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 87 out of 100 complete. metrics: {'eval/walltime': 2594.9453032016754, 'training/sps': 11376.417430968606, 'training/walltime': 7749.808414936066, 'training/envsteps': 87137280.0, 'training/actor_loss': Array(3.0841615, dtype=float32), 'training/alph_aloss': Array(-1.6719825e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.7744482, dtype=float32), 'training/log_alpha': Array(-2.4868855, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11781961, dtype=float32), 'training/sample_entropy': Array(-2.0002916, dtype=float32), 'eval/episode_reward': Array(278.39844, dtype=float32), 'eval/episode_success': Array(278.39844, dtype=float32), 'eval/episode_success_easy': Array(663.4922, dtype=float32), 'eval/episode_success_any': Array(0.390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.661728382110596, 'eval/sps': 3918.9597838339705}
Time elapsed: 2.874 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 88 out of 100 complete. metrics: {'eval/walltime': 2624.985566139221, 'training/sps': 11368.453719970195, 'training/walltime': 7836.369351387024, 'training/envsteps': 88121344.0, 'training/actor_loss': Array(3.1053646, dtype=float32), 'training/alph_aloss': Array(0.00012382, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.795812, dtype=float32), 'training/log_alpha': Array(-2.4904726, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11552522, dtype=float32), 'training/sample_entropy': Array(-1.9985912, dtype=float32), 'eval/episode_reward': Array(237.625, dtype=float32), 'eval/episode_success': Array(237.625, dtype=float32), 'eval/episode_success_easy': Array(660.5078, dtype=float32), 'eval/episode_success_any': Array(0.390625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.040262937545776, 'eval/sps': 4260.94805714964}
Time elapsed: 2.906 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 89 out of 100 complete. metrics: {'eval/walltime': 2649.461716413498, 'training/sps': 11378.780948874979, 'training/walltime': 7922.851726293564, 'training/envsteps': 89105408.0, 'training/actor_loss': Array(3.1313994, dtype=float32), 'training/alph_aloss': Array(7.207213e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.826328, dtype=float32), 'training/log_alpha': Array(-2.5033977, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11422342, dtype=float32), 'training/sample_entropy': Array(-1.99921, dtype=float32), 'eval/episode_reward': Array(306.16406, dtype=float32), 'eval/episode_success': Array(306.16406, dtype=float32), 'eval/episode_success_easy': Array(621.3672, dtype=float32), 'eval/episode_success_any': Array(0.4765625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 24.476150274276733, 'eval/sps': 5229.580573972938}
Time elapsed: 2.937 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 90 out of 100 complete. metrics: {'eval/walltime': 2671.4573798179626, 'training/sps': 11383.450558644008, 'training/walltime': 8009.298625230789, 'training/envsteps': 90089472.0, 'training/actor_loss': Array(3.151147, dtype=float32), 'training/alph_aloss': Array(-0.0002408, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8447695, dtype=float32), 'training/log_alpha': Array(-2.4952524, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1146137, dtype=float32), 'training/sample_entropy': Array(-2.003012, dtype=float32), 'eval/episode_reward': Array(214.05469, dtype=float32), 'eval/episode_success': Array(214.05469, dtype=float32), 'eval/episode_success_easy': Array(669.4453, dtype=float32), 'eval/episode_success_any': Array(0.40625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 21.99566340446472, 'eval/sps': 5819.328912535473}
Time elapsed: 2.967 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 91 out of 100 complete. metrics: {'eval/walltime': 2701.8594517707825, 'training/sps': 11432.364526194579, 'training/walltime': 8095.375656604767, 'training/envsteps': 91073536.0, 'training/actor_loss': Array(3.1678662, dtype=float32), 'training/alph_aloss': Array(0.00013172, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8615234, dtype=float32), 'training/log_alpha': Array(-2.4757082, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11382876, dtype=float32), 'training/sample_entropy': Array(-1.9985188, dtype=float32), 'eval/episode_reward': Array(223.72656, dtype=float32), 'eval/episode_success': Array(223.72656, dtype=float32), 'eval/episode_success_easy': Array(688.91406, dtype=float32), 'eval/episode_success_any': Array(0.375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 30.402071952819824, 'eval/sps': 4210.239361272476}
Time elapsed: 2.999 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 92 out of 100 complete. metrics: {'eval/walltime': 2735.5240478515625, 'training/sps': 11335.89218547752, 'training/walltime': 8182.18523311615, 'training/envsteps': 92057600.0, 'training/actor_loss': Array(3.183224, dtype=float32), 'training/alph_aloss': Array(-0.00015158, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.874239, dtype=float32), 'training/log_alpha': Array(-2.4791298, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.1127507, dtype=float32), 'training/sample_entropy': Array(-2.0019295, dtype=float32), 'eval/episode_reward': Array(389.2578, dtype=float32), 'eval/episode_success': Array(389.2578, dtype=float32), 'eval/episode_success_easy': Array(759.59375, dtype=float32), 'eval/episode_success_any': Array(0.5, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.66459608078003, 'eval/sps': 3802.2140438832844}
Time elapsed: 3.033 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 93 out of 100 complete. metrics: {'eval/walltime': 2759.251834630966, 'training/sps': 11401.105572702696, 'training/walltime': 8268.498265981674, 'training/envsteps': 93041664.0, 'training/actor_loss': Array(3.1799257, dtype=float32), 'training/alph_aloss': Array(6.912149e-06, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8691444, dtype=float32), 'training/log_alpha': Array(-2.47693, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11335301, dtype=float32), 'training/sample_entropy': Array(-2.0000176, dtype=float32), 'eval/episode_reward': Array(301.95312, dtype=float32), 'eval/episode_success': Array(301.95312, dtype=float32), 'eval/episode_success_easy': Array(647.3594, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 23.727786779403687, 'eval/sps': 5394.519142893985}
Time elapsed: 3.063 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 94 out of 100 complete. metrics: {'eval/walltime': 2792.4255905151367, 'training/sps': 11354.977039871472, 'training/walltime': 8355.161937475204, 'training/envsteps': 94025728.0, 'training/actor_loss': Array(3.169132, dtype=float32), 'training/alph_aloss': Array(-8.895734e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.861014, dtype=float32), 'training/log_alpha': Array(-2.4713042, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11340624, dtype=float32), 'training/sample_entropy': Array(-2.001153, dtype=float32), 'eval/episode_reward': Array(339.64062, dtype=float32), 'eval/episode_success': Array(339.64062, dtype=float32), 'eval/episode_success_easy': Array(672.4453, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.17375588417053, 'eval/sps': 3858.471752397429}
Time elapsed: 3.097 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 95 out of 100 complete. metrics: {'eval/walltime': 2824.452241420746, 'training/sps': 11400.52887501168, 'training/walltime': 8441.479336500168, 'training/envsteps': 95009792.0, 'training/actor_loss': Array(3.1754327, dtype=float32), 'training/alph_aloss': Array(0.00032474, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8599844, dtype=float32), 'training/log_alpha': Array(-2.4720712, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11301076, dtype=float32), 'training/sample_entropy': Array(-1.9962142, dtype=float32), 'eval/episode_reward': Array(257.26562, dtype=float32), 'eval/episode_success': Array(257.26562, dtype=float32), 'eval/episode_success_easy': Array(684.0469, dtype=float32), 'eval/episode_success_any': Array(0.3671875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 32.02665090560913, 'eval/sps': 3996.671408985263}
Time elapsed: 3.130 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 96 out of 100 complete. metrics: {'eval/walltime': 2857.9970378875732, 'training/sps': 11374.820072199811, 'training/walltime': 8527.991825819016, 'training/envsteps': 95993856.0, 'training/actor_loss': Array(3.1821582, dtype=float32), 'training/alph_aloss': Array(-0.00032889, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8662322, dtype=float32), 'training/log_alpha': Array(-2.4747808, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.11133516, dtype=float32), 'training/sample_entropy': Array(-2.00405, dtype=float32), 'eval/episode_reward': Array(326.84375, dtype=float32), 'eval/episode_success': Array(326.84375, dtype=float32), 'eval/episode_success_easy': Array(790.7578, dtype=float32), 'eval/episode_success_any': Array(0.453125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 33.54479646682739, 'eval/sps': 3815.7930135775246}
Time elapsed: 3.163 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 97 out of 100 complete. metrics: {'eval/walltime': 2884.3655862808228, 'training/sps': 11348.21298341439, 'training/walltime': 8614.707152843475, 'training/envsteps': 96977920.0, 'training/actor_loss': Array(3.1933632, dtype=float32), 'training/alph_aloss': Array(-0.00013673, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.8780181, dtype=float32), 'training/log_alpha': Array(-2.4567783, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10828043, dtype=float32), 'training/sample_entropy': Array(-2.0017085, dtype=float32), 'eval/episode_reward': Array(339.09375, dtype=float32), 'eval/episode_success': Array(339.09375, dtype=float32), 'eval/episode_success_easy': Array(837.89844, dtype=float32), 'eval/episode_success_any': Array(0.4609375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 26.36854839324951, 'eval/sps': 4854.267974522582}
Time elapsed: 3.194 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 98 out of 100 complete. metrics: {'eval/walltime': 2905.487711906433, 'training/sps': 11400.912052994261, 'training/walltime': 8701.021650791168, 'training/envsteps': 97961984.0, 'training/actor_loss': Array(3.194529, dtype=float32), 'training/alph_aloss': Array(-0.00041397, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.880874, dtype=float32), 'training/log_alpha': Array(-2.4387527, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10657993, dtype=float32), 'training/sample_entropy': Array(-2.0048454, dtype=float32), 'eval/episode_reward': Array(286.76562, dtype=float32), 'eval/episode_success': Array(286.76562, dtype=float32), 'eval/episode_success_easy': Array(826.5078, dtype=float32), 'eval/episode_success_any': Array(0.3671875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 21.12212562561035, 'eval/sps': 6059.996151372255}
Time elapsed: 3.224 hours
Available keys in episode_metrics: dict_keys(['reward', 'success', 'success_easy', 'success_hard'])
epoch 99 out of 100 complete. metrics: {'eval/walltime': 2924.748337984085, 'training/sps': 11460.039624616044, 'training/walltime': 8786.89081287384, 'training/envsteps': 98946048.0, 'training/actor_loss': Array(3.2196672, dtype=float32), 'training/alph_aloss': Array(-3.0072737e-05, dtype=float32), 'training/buffer_current_size': Array(10000., dtype=float32), 'training/categorical_accuracy': Array(0., dtype=float32), 'training/critic_loss': Array(3.9043927, dtype=float32), 'training/log_alpha': Array(-2.4268808, dtype=float32), 'training/logits_neg': Array(0., dtype=float32), 'training/logits_pos': Array(0., dtype=float32), 'training/logsumexp': Array(-0.10161687, dtype=float32), 'training/sample_entropy': Array(-2.000434, dtype=float32), 'eval/episode_reward': Array(296.73438, dtype=float32), 'eval/episode_success': Array(296.73438, dtype=float32), 'eval/episode_success_easy': Array(839.6953, dtype=float32), 'eval/episode_success_any': Array(0.4296875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 19.260626077651978, 'eval/sps': 6645.682205965146}
Time elapsed: 3.253 hours
wandb: 
wandb: Run history:
wandb:       eval/avg_episode_length ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           eval/episode_reward ▁▆█▅▆▇▇▄▅▆▆▆▆▅▆▅▆▅▄▅▆▆▅▄▅▅▅▄▄▅▆▅▅▅▄▄▄▅▆▅
wandb:          eval/episode_success ▁▆█▅▆▇▇▄▅▆▆▆▆▅▆▅▆▅▄▅▆▆▅▄▅▅▅▄▄▅▆▅▅▅▄▄▄▅▆▅
wandb:      eval/episode_success_any ▁▆█▅▆▇▇▅▆▇▆▆▆▆▆▆▇▇▅▆▇▇▇▅▇▆▆▆▅▅▇▇▇▆▆▆▆▇▇▇
wandb:     eval/episode_success_easy ▁██▃▅▆▆▅▆▆▆▆▆▅▆▅▆▆▅▆▆▆▅▄▅▄▃▄▄▄▅▄▅▅▄▅▅▅▇▇
wandb:          eval/epoch_eval_time █▆▇▆▇▇▃▂▆▅▆▆▃▅▆▂▆▅▃▆▇▆▆▅▆▂█▇▇▁▄▇▅▇▅▆▆▃▇▁
wandb:                      eval/sps ▁▂▁▂▂▂▅▆▂▃▃▂▅▃▂▇▂▃▅▂▂▂▂▃▂▇▁▂▁▇▄▁▃▂▃▃▂▅▂█
wandb:                 eval/walltime ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:           training/actor_loss ▆█▁▁▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂
wandb:           training/alph_aloss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:  training/buffer_current_size ▁▅██████████████████████████████████████
wandb: training/categorical_accuracy ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          training/critic_loss ██▂▁▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▄▄▄▄
wandb:             training/envsteps ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            training/log_alpha █▁▄▆▄▃▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄
wandb:           training/logits_neg ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           training/logits_pos ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            training/logsumexp ██▂▁▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▅▅▄▄▄▄▄▅▅▅▅▅▅▅
wandb:       training/sample_entropy █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                  training/sps ▁▆█▇▇█▇▇▇▇█▇█▇█▇▇█▇▇▇▇▇▇▇▇██████████████
wandb:             training/walltime ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:       eval/avg_episode_length 1000.0
wandb:           eval/episode_reward 296.73438
wandb:          eval/episode_success 296.73438
wandb:      eval/episode_success_any 0.42969
wandb:     eval/episode_success_easy 839.69531
wandb:          eval/epoch_eval_time 19.26063
wandb:                      eval/sps 6645.68221
wandb:                 eval/walltime 2924.74834
wandb:           training/actor_loss 3.21967
wandb:           training/alph_aloss -3e-05
wandb:  training/buffer_current_size 10000.0
wandb: training/categorical_accuracy 0.0
wandb:          training/critic_loss 3.90439
wandb:             training/envsteps 98946048.0
wandb:            training/log_alpha -2.42688
wandb:           training/logits_neg 0.0
wandb:           training/logits_pos 0.0
wandb:            training/logsumexp -0.10162
wandb:       training/sample_entropy -2.00043
wandb:                  training/sps 11460.03962
wandb:             training/walltime 8786.89081
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync ./wandb/offline-run-20241104_011346-ctq9jotu
wandb: Find logs at: ./wandb/offline-run-20241104_011346-ctq9jotu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
